{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм автоматического поиска ошибок в транскрибациях \n",
    "## на основе марковских цепей и векторной модели Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Авторы:\n",
    "\n",
    "#### Смирнова Екатерина,\n",
    "#### Черная Анастасия "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import opencorpora \n",
    "import pickle\n",
    "import nltk\n",
    "import gensim\n",
    "import wget\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer() #сразу же инициализируем морфанализатор\n",
    "\n",
    "from num2words import num2words\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "### Корпуса для обучения языковой модели на основе марковских цепей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состав объединенного корпуса: открытый корпус русского языка проекта OpenCorporа + корпус субтитров к фильмам и сериалам + корпус сказок для детей и взрослых"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус opencorpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем тренировочный корпус - открытый корпус русского языка проекта [OpenCorpora](http://opencorpora.org/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на корпус находится [здесь](http://opencorpora.org/?page=downloads): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = opencorpora.load('annot.opcorpora.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Corpus revision=4566500 docs:4030 tokens:1989618>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Количество документов и токенов:\n",
    "train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вытаскиваем токены и текст из них (по атрибуту source). Для этого применяем source из пакета opencorpora-tools:\n",
    "#Лучше обойтись без токенизации от nltk, а взять токены из корпуса с помощью метода tokens - здесь чище токенизация\n",
    "train_corp = [elem.source for elem in train_corpus.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['«', 'Школа', 'злословия', '»', 'учит']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токенов в тренировочном корпусе opencorpora до предобработки:  1989618\n"
     ]
    }
   ],
   "source": [
    "print('Количество токенов в тренировочном корпусе opencorpora до предобработки: ', len(train_corp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус субтитров к фильмам и сериалам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка](https://github.com/Desklop/Russian_subtitles_dataset/tree/master/data) на загрузку файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = open('subtitles_ru.txt', mode = 'r', encoding = \"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет, пап.\\nдоброе утро, девочки.\\nжаль, меня не б'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitles[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус сказок для детей и взрослых"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка](https://www.kaggle.com/idoldev/adult-and-child-russian-tales-dataset-with-label) на загрузку файла. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tales_df = pd.read_csv('tales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tale</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Снежно белый снеговик Он не мал и не велик, Сн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Снеговик из детской сказки Раскраснелась детво...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Снежная баба Мы снежную бабу слепили на славу....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ком, комочек и комок Что стоишь и ждёшь, дружо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Лепим снеговика Лепит с самого утра Детвора сн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tale  Label\n",
       "0  Снежно белый снеговик Он не мал и не велик, Сн...      1\n",
       "1  Снеговик из детской сказки Раскраснелась детво...      1\n",
       "2  Снежная баба Мы снежную бабу слепили на славу....      1\n",
       "3  Ком, комочек и комок Что стоишь и ждёшь, дружо...      1\n",
       "4  Лепим снеговика Лепит с самого утра Детвора сн...      1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tales = list(tales_df.Tale.values)\n",
    "tales = ' '.join([str(sent) for sent in tales])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корпус транскрибаций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка](https://github.com/smekur/Spoken_Corpora_with_Kaldi/tree/master/Транскрибации/all_transcripts.xlsx) на загрузку корпуса с транскрибациями "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = pd.read_excel('all_transcripts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>alphacep_transcripts</th>\n",
       "      <th>abk_transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDS_001-f-z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>азат аллё а потом вот опять заново уже а по по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDS_002-f-z</td>\n",
       "      <td>слуга прошла подальше от прошла галлия а этот ...</td>\n",
       "      <td>хорошо да да гулять а я я ульянова задачка у н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDS_003-f-z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>например спасибо я назад одна с нами наименее ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDS_004-m-z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>я я готова я не пошёл</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDS_005-m-z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>говорите а да манакова</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      audio_ID                               alphacep_transcripts  \\\n",
       "0  NDS_001-f-z                                                NaN   \n",
       "1  NDS_002-f-z  слуга прошла подальше от прошла галлия а этот ...   \n",
       "2  NDS_003-f-z                                                NaN   \n",
       "3  NDS_004-m-z                                                NaN   \n",
       "4  NDS_005-m-z                                                NaN   \n",
       "\n",
       "                                     abk_transcripts  \n",
       "0  азат аллё а потом вот опять заново уже а по по...  \n",
       "1  хорошо да да гулять а я я ульянова задачка у н...  \n",
       "2  например спасибо я назад одна с нами наименее ...  \n",
       "3                              я я готова я не пошёл  \n",
       "4                             говорите а да манакова  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. транскрибации подкорпуса NDS получились очень плохого качества из-за специфики детской речи, в рамках данного проекта рассмотрим только подкорпуса Pic и Sib. \n",
    "\n",
    "Отфильтруем из общего датафрейма нужные нам транскрибации и разберем их по двум датафреймам в заивисмости от модели транскрибатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_alpha = trans.loc[\n",
    "       (trans.audio_ID.str.contains('Sib')|trans.audio_ID.str.contains('Pic'))&trans.alphacep_transcripts.notnull(),\n",
    "       ['audio_ID','alphacep_transcripts']\n",
    "    ]\n",
    "trans_abk = trans.loc[\n",
    "       (trans.audio_ID.str.contains('Sib')|trans.audio_ID.str.contains('Pic'))&trans.abk_transcripts.notnull(),\n",
    "       ['audio_ID','abk_transcripts']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>alphacep_transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pic-RUS_01-f_Pr-R.zip</td>\n",
       "      <td>жилбыл один дяденька по его жены скоро должно ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pic-RUS_01-f_Ski-T.zip</td>\n",
       "      <td>генин жизни одного очень увлекающийся спортом ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pic-RUS_02-f_Pr-R.zip</td>\n",
       "      <td>однозначным был день рождения мышь решил подар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pic-RUS_02-f_Ski-T.zip</td>\n",
       "      <td>этот человек встал рано утром позавтракал а по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Pic-RUS_03-m_Ski-R.zip</td>\n",
       "      <td>знакомым мне здесь рассказали одну смешную и п...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  audio_ID                               alphacep_transcripts\n",
       "35   Pic-RUS_01-f_Pr-R.zip  жилбыл один дяденька по его жены скоро должно ...\n",
       "38  Pic-RUS_01-f_Ski-T.zip  генин жизни одного очень увлекающийся спортом ...\n",
       "39   Pic-RUS_02-f_Pr-R.zip  однозначным был день рождения мышь решил подар...\n",
       "42  Pic-RUS_02-f_Ski-T.zip  этот человек встал рано утром позавтракал а по...\n",
       "45  Pic-RUS_03-m_Ski-R.zip  знакомым мне здесь рассказали одну смешную и п..."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>abk_transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pic-RUS_01-f_Pr-R.zip</td>\n",
       "      <td>жил был один дяденька его жены скоро должно бы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pic-RUS_01-f_Pr-T.zip</td>\n",
       "      <td>товарищ тут с ним случилось проблема у его жен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pic-RUS_01-f_Ski-R.zip</td>\n",
       "      <td>жил был один молодой человек это молодой челов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pic-RUS_01-f_Ski-T.zip</td>\n",
       "      <td>день жизнь одного точне увлекающейся спорту му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pic-RUS_02-f_Pr-R.zip</td>\n",
       "      <td>однозначно был день рождения её муж решил пода...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  audio_ID                                    abk_transcripts\n",
       "35   Pic-RUS_01-f_Pr-R.zip  жил был один дяденька его жены скоро должно бы...\n",
       "36   Pic-RUS_01-f_Pr-T.zip  товарищ тут с ним случилось проблема у его жен...\n",
       "37  Pic-RUS_01-f_Ski-R.zip  жил был один молодой человек это молодой челов...\n",
       "38  Pic-RUS_01-f_Ski-T.zip  день жизнь одного точне увлекающейся спорту му...\n",
       "39   Pic-RUS_02-f_Pr-R.zip  однозначно был день рождения её муж решил пода..."
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_abk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка тренировочных корпусов, токенизация, лемматизация и статистика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обработки цифр: превращаем цифры в слова.\n",
    "\n",
    "На вход подаем список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Используем готовую функцию num2words из библиотеки num2words:\n",
    "def convert_num2words (tokens_list):\n",
    "    for i in range(len(tokens_list)):\n",
    "        if re.fullmatch(r'\\d+', tokens_list[i]) is not None:\n",
    "            tokens_list[i] = num2words(tokens_list[i], lang='ru')\n",
    "    new_tokens_list =' '.join(tokens_list).split() #чтобы сложные числительные разбить по словам и сохранить порядок следования токенов \n",
    "    return new_tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для предобработки:\n",
    "- убирает токены-пунктуатры\n",
    "- приводит к нижему регистру\n",
    "- заменяет 'ё' на 'е'\n",
    "\n",
    "На вход подаем список токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokens(tokens_list):\n",
    "    fine_tokens = [re.sub(r'ё', r'е', elem.lower()) for elem in tokens_list if re.fullmatch(r'(?:.*[А-Яа-яЁё]+.*)', elem) is not None]\n",
    "    return fine_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая лемматизирует словоформы-токены с помощью морфанализатора pymorphy2\n",
    "\n",
    "На вход подаем список токенов-словоформ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_analyzator(tokens):\n",
    "    morph_analized = [morph.normal_forms(token)[0] for token in tokens]\n",
    "    return morph_analized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка корпуса opencorpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Конвертируем цифры в слова:\n",
    "train_corp = convert_num2words(train_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делаем базовую предобработку (подробно см. в описании функции):\n",
    "preprocessed_train_corp = preprocess_tokens(train_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['школа',\n",
       " 'злословия',\n",
       " 'учит',\n",
       " 'прикусить',\n",
       " 'язык',\n",
       " 'сохранится',\n",
       " 'ли',\n",
       " 'градус',\n",
       " 'дискуссии',\n",
       " 'в']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_corp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получаем словарь уникальных словоформ:\n",
    "vocab_opencorp = set(preprocessed_train_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Лемматизируем корпус:\n",
    "lemmas_opencorpora = morph_analyzator(preprocessed_train_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий объем корпуса opencorpora после предобработки: 1612160\n"
     ]
    }
   ],
   "source": [
    "print(\"Общий объем корпуса opencorpora после предобработки: \" +str(len(preprocessed_train_corp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов в корпусе opencorpora после предобработки: 163022\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных токенов в корпусе opencorpora после предобработки: \" +str(len(set(preprocessed_train_corp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных лемм в корпусе opencorpora:  65335\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных лемм в корпусе opencorpora: \", str(len(set(lemmas_opencorpora))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус субтитров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала токенизируем с помощью nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36367392"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Токенизируем с помощью nltk.word_tokenize:\n",
    "subtitles_tokens = word_tokenize(subtitles)\n",
    "len(subtitles_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles_corp = convert_num2words(subtitles_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_subtitles = preprocess_tokens(subtitles_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['привет',\n",
       " 'пап',\n",
       " 'доброе',\n",
       " 'утро',\n",
       " 'девочки',\n",
       " 'жаль',\n",
       " 'меня',\n",
       " 'не',\n",
       " 'было',\n",
       " 'этим']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_subtitles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_subtitles = set(preprocessed_subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 2 µs, total: 9 µs\n",
      "Wall time: 48.2 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "lemmas_subtitles = morph_analyzator(preprocessed_subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий объем корпуса субтитров после предобработки: 28241077\n"
     ]
    }
   ],
   "source": [
    "print(\"Общий объем корпуса субтитров после предобработки: \" +str(len(preprocessed_subtitles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов в корпусе субтитров после предобработки: 482251\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных токенов в корпусе субтитров после предобработки: \" +str(len(set(preprocessed_subtitles))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных лемм в корпусе субтитров:  230166\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных лемм в корпусе субтитров: \", str(len(set(lemmas_subtitles))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус сказок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прежде избавляемся от \\xa0 (в сказках есть no-brake space): \n",
    "tales = normalize('NFKD', tales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Снежно белый снеговик Он не мал и не велик, Снежно белый снеговик. У него морковкой нос, Очень лю'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12241202"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2387363"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales_tokens = word_tokenize(tales)\n",
    "len(tales_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Снежно', 'белый', 'снеговик', 'Он', 'не', 'мал', 'и', 'не', 'велик', ',']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tales_corp = convert_num2words(tales_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2393444"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tales_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tales = preprocess_tokens(tales_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tales = set(preprocessed_tales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_tales = morph_analyzator(preprocessed_tales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий объем корпуса сказок после предобработки: 1894231\n"
     ]
    }
   ],
   "source": [
    "print(\"Общий объем корпуса сказок после предобработки: \" +str(len(preprocessed_tales)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов в корпусе сказок после предобработки: 149651\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных токенов в корпусе сказок после предобработки: \" +str(len(set(preprocessed_tales))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных лемм в корпусе субтитров:  68014\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных лемм в корпусе субтитров: \", str(len(set(lemmas_tales))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение обучающих корпусов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_all = lemmas_opencorpora+lemmas_subtitles+lemmas_tales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['школа',\n",
       " 'злословие',\n",
       " 'учить',\n",
       " 'прикусить',\n",
       " 'язык',\n",
       " 'сохраниться',\n",
       " 'ли',\n",
       " 'градус',\n",
       " 'дискуссия',\n",
       " 'в',\n",
       " 'новый',\n",
       " 'сезон',\n",
       " 'великолепный',\n",
       " 'школа',\n",
       " 'злословие',\n",
       " 'вернуться',\n",
       " 'в',\n",
       " 'эфир',\n",
       " 'после',\n",
       " 'летний',\n",
       " 'каникулы',\n",
       " 'в',\n",
       " 'новый',\n",
       " 'формат',\n",
       " 'в',\n",
       " 'история',\n",
       " 'программа',\n",
       " 'это',\n",
       " 'уже',\n",
       " 'не',\n",
       " 'один',\n",
       " 'ребрендинга',\n",
       " 'сейчас',\n",
       " 'с',\n",
       " 'труд',\n",
       " 'можно',\n",
       " 'припомнить',\n",
       " 'что',\n",
       " 'начинаться',\n",
       " 'школа',\n",
       " 'на',\n",
       " 'канал',\n",
       " 'культура',\n",
       " 'как',\n",
       " 'стандартный',\n",
       " 'ток-шоу',\n",
       " 'который',\n",
       " 'отличаться',\n",
       " 'от',\n",
       " 'другой',\n",
       " 'кухонный',\n",
       " 'обсуждение',\n",
       " 'гость',\n",
       " 'что',\n",
       " 'называться',\n",
       " 'за',\n",
       " 'глаз',\n",
       " 'и',\n",
       " 'неожиданный',\n",
       " 'персона',\n",
       " 'в',\n",
       " 'качество',\n",
       " 'ведущий',\n",
       " 'писательница',\n",
       " 'татьяна',\n",
       " 'толстой',\n",
       " 'и',\n",
       " 'сценаристка',\n",
       " 'дуня',\n",
       " 'смирнов',\n",
       " 'вроде',\n",
       " 'бы',\n",
       " 'не',\n",
       " 'вполне',\n",
       " 'соответствовать',\n",
       " 'принятый',\n",
       " 'на',\n",
       " 'российский',\n",
       " 'телевидение',\n",
       " 'стандарт',\n",
       " 'телеведущая',\n",
       " 'впрочем',\n",
       " 'на',\n",
       " 'канал',\n",
       " 'культура',\n",
       " 'в',\n",
       " 'роль',\n",
       " 'телеведущая',\n",
       " 'выступать',\n",
       " 'и',\n",
       " 'писатель',\n",
       " 'и',\n",
       " 'композитор',\n",
       " 'так',\n",
       " 'что',\n",
       " 'в',\n",
       " 'это',\n",
       " 'ничто',\n",
       " 'сверхъестественный',\n",
       " 'не']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_all[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество лемм в объединенном корпусе:  31747468\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество лемм в объединенном корпусе: \", str(len(lemmas_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных лемм в объединенном корпусе:  286016\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество уникальных лемм в объединенном корпусе: \", str(len(set(lemmas_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем лемматизированный корпус в файл: \n",
    "with open('lemmas_train_corp1.txt', 'w', encoding='utf-8') as file:\n",
    "    file = file.write(' '.join(lemmas_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание объединенного словаря словоформ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocab_opencorp.union(vocab_subtitles, vocab_tales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592898"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем объединенный словарь словоформ в файл: \n",
    "with open('wordforms_train_corp1.txt', 'w', encoding='utf-8') as file:\n",
    "    file = file.write(' '.join(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Список вводных слов и частотных дискурсивных маркеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка](https://github.com/smekur/Spoken_Corpora_with_Kaldi/tree/master/mistakes_search/dictionaries_txt) для скачивания "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный список создан самостоятельно на основе [списка]('http://new.gramota.ru/spravka/punctum/punctum-alphabet') из источника Грамота.ру, \n",
    "а также анализа частотных дискурсивных слов в золотом стандарте для наших транскрибаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parenthesis_rus.txt', encoding='utf-8') as file:\n",
    "    parenthesis_words = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['безусловно',\n",
       " 'бесспорно',\n",
       " 'бывает',\n",
       " 'бывало',\n",
       " 'вернее',\n",
       " 'верно',\n",
       " 'вероятно',\n",
       " 'видать',\n",
       " 'видимо',\n",
       " 'видно']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parenthesis_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Список частотных слов с дефисом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка](https://github.com/smekur/Spoken_Corpora_with_Kaldi/tree/master/mistakes_search/dictionaries_txt) для скачивания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список создан самостоятельно на основе слов с дефисом из обучающего корпуса и словаря частотных лемм Шарова и Ляшевской"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_with_hyphen.txt', encoding='utf-8') as file:\n",
    "    hyphened_words = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Марковская цепь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подсчет условных частот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(lemmas_all))#для лемматизированного объединенного корпуса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'на': 406, 'по': 63, 'с': 30, 'в': 28, 'я': 11, 'и': 9, 'он': 8, 'не': 8, 'вместе': 7, 'ты': 6, ...})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfreq['кататься']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем словарь модели c помощью pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cfreq = open(\"cfreq_corpus1.pickle\" , \"wb\" )\n",
    "pickle.dump(cfreq, save_cfreq)\n",
    "save_cfreq.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подсчет условных вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)#для лемматизированного объединенного корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.338916314393528e-05"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cprob['он'].prob('свалиться')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем словарь условных вероятностей модели c помощью pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cprob = open(\"cprob_corpus1.pickle\" , \"wb\" )\n",
    "pickle.dump(cprob, save_cprob)\n",
    "save_cprob.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объявление функций для предобработки тестового корпуса и нахождения ошибок текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для предобработки текста транскрибации: замена ё/е, составление биграм\n",
    "Аргументы:\n",
    "    text - исследуемый текст\n",
    "    parenthesis - если True, то мы исключаем из текста транскрибации вводные и частотные дискурсивные маркеры\n",
    "Вывод:\n",
    "    список биграм текста \n",
    "'''\n",
    "\n",
    "def text_preprocess(text, parenthesis = True):\n",
    "    text = text.replace('ё','е')\n",
    "    if parenthesis ==True:\n",
    "        splt_text = text.split() #разобьем на слова текст и проверим, если слово является вводным или дискурсивным маркером, мы его исключаем из обработки\n",
    "        for word in splt_text.copy():\n",
    "            if word in parenthesis_words: #список вводных слов и дискурсивных маркеров \n",
    "                splt_text.remove(word)\n",
    "        text = ' '.join(splt_text) #собираем слова текста в одну строку\n",
    "        \n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(2,2),\n",
    "                                    token_pattern=r'[а-я-]+', min_df=1)\n",
    "    analyze = bigram_vectorizer.build_analyzer()\n",
    "    bigrams = analyze(text) \n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для предобработки текста транскрибации: вставка дефиса для случаев \"когдато\"\n",
    "Аргументы:\n",
    "    word - исследуемое слово\n",
    "    words_with_hyphen - справочник слов с дефисом\n",
    "Вывод:\n",
    "    слово с дефисом \n",
    "'''\n",
    "\n",
    "def insert_hyphen(word, words_with_hyphen):\n",
    "    splits = [(word[:i], word[i:]) for i in range (len(word) - 1)]\n",
    "    for L, R in splits:\n",
    "        if L + '-' + R in words_with_hyphen:\n",
    "            word = L + '-' + R\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для предобработки текста транскрибации: замена случаев \"когдато\" на слова с дефисом\n",
    "Аргументы:\n",
    "    text - исследуемый текст\n",
    "    words_with_hyphen - справочник слов с дефисом\n",
    "Вывод:\n",
    "    скорректированный текст \n",
    "'''\n",
    "\n",
    "def insert_hyphen_in_text(text, words_with_hyphen):\n",
    "    correct_text = ''\n",
    "    correct_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        correct_word = insert_hyphen(word, words_with_hyphen)\n",
    "        if correct_word != word:\n",
    "            correct_words.append(correct_word)\n",
    "        correct_text = correct_text + correct_word + ' '\n",
    "    return correct_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для нахождения ошибок транскрибаций\n",
    "\n",
    "Параметры:\n",
    "    text - исходный текст для анализа (str)\n",
    "    model_freq - словарь частот совместной встречаемости, полученный на основе обучающего корпуса (nltk.probability.ConditionalFreqDist)\n",
    "    model_prob - словарь вероятности совместной встречаемости, полученный на основе обучающего корпуса (nltk.probability.ConditionalProbDist)\n",
    "    lemma - лемматизация слов в биграмах - по умолчанию True (bool)\n",
    "    threshold - порог для установления \"ошибки\" транскрибации - по умолчанию 0 (int)\n",
    "\n",
    "Вывод:\n",
    "    mistakes - список биграмм, в которых есть ошибка транскрибации (list)\n",
    "    bigrams_prob_dict - словарь, содержащий биграммы, в которых нет ошибки, и вероятности совместной встречаемости слов биграмм не ниже порога (dict)\n",
    "    no_such_word - список биграмм, в которых хотя бы одно слово отсутствует в словаре обучающего корпуса (list)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def find_mistakes(text, model_freq, model_prob, lemma = True, threshold = 0):\n",
    "    mistakes = [] #переменная для хранения \"ошибок\"\n",
    "    no_such_word = [] #переменная для хранения биграм, в которых хотя бы одно слово отсутствует в обучающем корпусе\n",
    "    bigrams_prob_dict = {} #переменная для хранения \"правильных\" биграм и их вероятностей\n",
    "    \n",
    "    TEXT = text_preprocess(text) #список биграм текста\n",
    "    \n",
    "    for bigram in TEXT:\n",
    "        big = bigram.split()\n",
    "        if lemma == True:\n",
    "            big = [morph.normal_forms(token)[0] for token in big] #лемматизируем слова в биграмах\n",
    "    \n",
    "        if model_freq[big[0]]=={} or model_freq[big[1]]=={}: #проверяем, есть ли слово в нашем тренировочном корпусе\n",
    "            no_such_word.append(bigram)\n",
    "            continue\n",
    "    \n",
    "        else:\n",
    "            #считаем ошибкой, если вероятность совместной встречаемости меньше или равна установленному порогу\n",
    "            if model_prob[big[0]].prob(big[1]) <= threshold: \n",
    "                mistakes.append(bigram)\n",
    "            else:\n",
    "                bigrams_prob_dict[bigram] = model_prob[big[0]].prob(big[1])\n",
    "                \n",
    "    print('\\tВсего ошибок: ', len(mistakes), ' из ', len(TEXT))\n",
    "    print('\\tКоличество биграм с отсутствующим в словаре словом: ', len(no_such_word))\n",
    "    \n",
    "    return mistakes, bigrams_prob_dict, no_such_word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для нахождения слов-ошибок в биграммах - кандидатах на ошибку\n",
    "\n",
    "Аргументы:\n",
    "    mistakes - список биграмм-кандидатов на ошибку из рассматриваемого\n",
    "    bigrams_prob_dict - словарь с \"правильными\" биграмами того же текста\n",
    "    \n",
    "Вывод:\n",
    "    словарь вида: {`слово-ошибка`: `биграма-кандидат`}\n",
    "'''\n",
    "\n",
    "def find_true_mistakes(mistakes, bigrams_prob_dict):\n",
    "    true_mistakes = {}\n",
    "    for mist in mistakes:\n",
    "        for word in mist.split():\n",
    "            bigs = []\n",
    "            for key in bigrams_prob_dict:\n",
    "                bigs += key.split()\n",
    "            if word in bigs:\n",
    "                continue\n",
    "            else:\n",
    "                if word not in true_mistakes:\n",
    "                    true_mistakes[word]= mist\n",
    "    return true_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для нахождения слов в словаре тренировочного корпуса, схожих исходному по расстоянию Левенштейна\n",
    "\n",
    "Аргументы:\n",
    "    voc - словарь тренировочного корпуса (слова не лемматизированы!)\n",
    "    true_mistakes - словарь слов-ошибок и их биграм\n",
    "\n",
    "Вывод:\n",
    "    словарь вида {`слово-ошибка`: [`список схожих слов`]}\n",
    "'''\n",
    "\n",
    "\n",
    "def find_variation(voc, true_mistakes):\n",
    "   \n",
    "    variates = {}\n",
    "    for mistake in true_mistakes:\n",
    "        words = []\n",
    "        for word in voc:\n",
    "            \n",
    "            if fuzz.ratio(mistake, word) > 80: \n",
    "                words.append(word)\n",
    "        variates[mistake] = words\n",
    "    \n",
    "    return variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для поиска ошибок 2-х категорий в тексте транскрибации:\n",
    "1-я категория - вероятность схожего слова, найденного по расстоянию Левенштейна, в данной биграме выше,чем вероятность исходного слова;\n",
    "2-я категория - вероятность схожего слова та же или ниже (то есть замена не дала результатов);\n",
    "\n",
    "Аргументы:\n",
    "    leven_mist - словарь, где ключ - исходное слово-ошибка, значение - список схожих слов по Левенштейну\n",
    "    true_mistakes - словарь слов-ошибок и их биграм\n",
    "    cprob_all - модель для подсчета условной вероятности слов в биграме\n",
    "\n",
    "Вывод:\n",
    "    first_mistakes - список слов первой категории\n",
    "    second_mistakes - список слов второй категории\n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "def categorize_mistakes(leven_mist, true_mistakes, cprob_all):\n",
    "    \n",
    "    first_mistakes = []\n",
    "    second_mistakes = []\n",
    "    new_words = []\n",
    "    \n",
    "    for key in leven_mist:\n",
    "        candidates = [morph.normal_forms(cand)[0] for cand in leven_mist[key]]\n",
    "                      \n",
    "        pair = ''.join([word for word in true_mistakes[key].split() if word != key])\n",
    "        pair_lem = morph.normal_forms(pair)[0]\n",
    "        key_lem = morph.normal_forms(key)[0]\n",
    "        \n",
    "        for cand in candidates:\n",
    "            if cand != key_lem:\n",
    "                if cprob_all[cand].prob(pair_lem)> 0:\n",
    "                    first_mistakes.append(key)\n",
    "                    new_words.append(cand)\n",
    "                    break\n",
    "    \n",
    "        second_mistakes.append(key)\n",
    "    return first_mistakes, second_mistakes, new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с транскрибациями (только марковская цепь)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование модели с марковской цепью, **с учетом вводных слов и дискурсивных маркеров в транскрибациях**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус транскрибатора Alphacep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 3 µs, total: 13 µs\n",
      "Wall time: 70.3 µs\n",
      "Обрабатываю ряд  35\n",
      "\tВсего ошибок:  24  из  137\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  38\n",
      "\tВсего ошибок:  15  из  81\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  3\n",
      "Обрабатываю ряд  39\n",
      "\tВсего ошибок:  12  из  78\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  42\n",
      "\tВсего ошибок:  5  из  65\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  45\n",
      "\tВсего ошибок:  19  из  83\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  46\n",
      "\tВсего ошибок:  16  из  68\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  52\n",
      "\tВсего ошибок:  31  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  54\n",
      "\tВсего ошибок:  15  из  106\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  55\n",
      "\tВсего ошибок:  5  из  39\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  58\n",
      "\tВсего ошибок:  11  из  58\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  59\n",
      "\tВсего ошибок:  27  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  60\n",
      "\tВсего ошибок:  29  из  129\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  62\n",
      "\tВсего ошибок:  16  из  94\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  64\n",
      "\tВсего ошибок:  30  из  105\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  65\n",
      "\tВсего ошибок:  22  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  66\n",
      "\tВсего ошибок:  20  из  96\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  73\n",
      "\tВсего ошибок:  54  из  176\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Обрабатываю ряд  77\n",
      "\tВсего ошибок:  110  из  322\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Обрабатываю ряд  79\n",
      "\tВсего ошибок:  93  из  285\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  7\n",
      "Обрабатываю ряд  84\n",
      "\tВсего ошибок:  61  из  248\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  14\n",
      "Обрабатываю ряд  85\n",
      "\tВсего ошибок:  56  из  175\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Обрабатываю ряд  87\n",
      "\tВсего ошибок:  101  из  443\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  26\n",
      "Обрабатываю ряд  88\n",
      "\tВсего ошибок:  36  из  105\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  8\n",
      "Обрабатываю ряд  89\n",
      "\tВсего ошибок:  91  из  369\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  14\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "trans_alpha['mistakes'] = ''\n",
    "trans_alpha['bigram_mist'] = ''\n",
    "trans_alpha['new_words'] = ''\n",
    "trans_alpha['mistakes_1st_type'] = ''\n",
    "trans_alpha['mistakes_2nd_type'] = ''\n",
    "trans_alpha['absent_words'] = ''\n",
    "\n",
    "\n",
    "for row in trans_alpha.alphacep_transcripts.index:\n",
    "    print('Обрабатываю ряд ', row)\n",
    "    text = insert_hyphen_in_text(trans_alpha.alphacep_transcripts[row], hyphened_words)\n",
    "    mistakes, bigrams_prob_dict, no_such_word = find_mistakes(text, cfreq, cprob)\n",
    "    true_mistakes = find_true_mistakes(mistakes, bigrams_prob_dict)\n",
    "    leven_mist = find_variation(vocab, true_mistakes)\n",
    "    \n",
    "    first_mistakes, second_mistakes, new_words = categorize_mistakes(leven_mist, true_mistakes, cprob)\n",
    "    \n",
    "    trans_alpha['mistakes'][row] = ', '.join([key for key in true_mistakes])\n",
    "    trans_alpha['bigram_mist'][row] = ', '.join([true_mistakes[key] for key in true_mistakes])\n",
    "    trans_alpha['new_words'][row] =', '.join(new_words)\n",
    "    trans_alpha['absent_words'][row] = ', '.join(no_such_word)\n",
    "    trans_alpha['mistakes_1st_type'][row] = ', '.join(first_mistakes)\n",
    "    trans_alpha['mistakes_2nd_type'][row] = ', '.join(second_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>alphacep_transcripts</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>bigram_mist</th>\n",
       "      <th>new_words</th>\n",
       "      <th>mistakes_1st_type</th>\n",
       "      <th>mistakes_2nd_type</th>\n",
       "      <th>absent_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pic-RUS_01-f_Pr-R.zip</td>\n",
       "      <td>жилбыл один дяденька по его жены скоро должно ...</td>\n",
       "      <td>дяденька, плот, ночного, посол, салон, наставь...</td>\n",
       "      <td>один дяденька, случится плот, дяденька ночного...</td>\n",
       "      <td>дядька, ставить</td>\n",
       "      <td>дяденька, наставь</td>\n",
       "      <td>дяденька, плот, ночного, посол, салон, наставь...</td>\n",
       "      <td>посол варт, варт салон</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pic-RUS_01-f_Ski-T.zip</td>\n",
       "      <td>генин жизни одного очень увлекающийся спортом ...</td>\n",
       "      <td>хочется, партийный, товарищ, тоесть, природу, ...</td>\n",
       "      <td>катался хочется, хочется партийный, партийный ...</td>\n",
       "      <td>хотеть</td>\n",
       "      <td>хочется</td>\n",
       "      <td>хочется, партийный, товарищ, тоесть, природу, ...</td>\n",
       "      <td>генин жизни, и норг, норг тоесть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pic-RUS_02-f_Pr-R.zip</td>\n",
       "      <td>однозначным был день рождения мышь решил подар...</td>\n",
       "      <td>однозначным, мышь, посылала</td>\n",
       "      <td>однозначным был, рождения мышь, в посылала</td>\n",
       "      <td>однозначно, подослать</td>\n",
       "      <td>однозначным, посылала</td>\n",
       "      <td>однозначным, мышь, посылала</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pic-RUS_02-f_Ski-T.zip</td>\n",
       "      <td>этот человек встал рано утром позавтракал а по...</td>\n",
       "      <td>наложены, божественного</td>\n",
       "      <td>отправился наложены, голову божественного</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>наложены, божественного</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Pic-RUS_03-m_Ski-R.zip</td>\n",
       "      <td>знакомым мне здесь рассказали одну смешную и п...</td>\n",
       "      <td>нагорных, доскачет, поехать, наложением, слышь</td>\n",
       "      <td>лыжах нагорных, дороге доскачет, позвать поеха...</td>\n",
       "      <td>горный</td>\n",
       "      <td>нагорных</td>\n",
       "      <td>нагорных, доскачет, поехать, наложением, слышь</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  audio_ID                               alphacep_transcripts  \\\n",
       "35   Pic-RUS_01-f_Pr-R.zip  жилбыл один дяденька по его жены скоро должно ...   \n",
       "38  Pic-RUS_01-f_Ski-T.zip  генин жизни одного очень увлекающийся спортом ...   \n",
       "39   Pic-RUS_02-f_Pr-R.zip  однозначным был день рождения мышь решил подар...   \n",
       "42  Pic-RUS_02-f_Ski-T.zip  этот человек встал рано утром позавтракал а по...   \n",
       "45  Pic-RUS_03-m_Ski-R.zip  знакомым мне здесь рассказали одну смешную и п...   \n",
       "\n",
       "                                             mistakes  \\\n",
       "35  дяденька, плот, ночного, посол, салон, наставь...   \n",
       "38  хочется, партийный, товарищ, тоесть, природу, ...   \n",
       "39                        однозначным, мышь, посылала   \n",
       "42                            наложены, божественного   \n",
       "45     нагорных, доскачет, поехать, наложением, слышь   \n",
       "\n",
       "                                          bigram_mist              new_words  \\\n",
       "35  один дяденька, случится плот, дяденька ночного...        дядька, ставить   \n",
       "38  катался хочется, хочется партийный, партийный ...                 хотеть   \n",
       "39         однозначным был, рождения мышь, в посылала  однозначно, подослать   \n",
       "42          отправился наложены, голову божественного                          \n",
       "45  лыжах нагорных, дороге доскачет, позвать поеха...                 горный   \n",
       "\n",
       "        mistakes_1st_type                                  mistakes_2nd_type  \\\n",
       "35      дяденька, наставь  дяденька, плот, ночного, посол, салон, наставь...   \n",
       "38                хочется  хочется, партийный, товарищ, тоесть, природу, ...   \n",
       "39  однозначным, посылала                        однозначным, мышь, посылала   \n",
       "42                                                   наложены, божественного   \n",
       "45               нагорных     нагорных, доскачет, поехать, наложением, слышь   \n",
       "\n",
       "                        absent_words  \n",
       "35            посол варт, варт салон  \n",
       "38  генин жизни, и норг, норг тоесть  \n",
       "39                                    \n",
       "42                                    \n",
       "45                                    "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_alpha.to_excel('trans_alpha_mark_ch.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "Обрабатываю ряд  35\n",
      "\tВсего ошибок:  10  из  148\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  36\n",
      "\tВсего ошибок:  21  из  135\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  37\n",
      "\tВсего ошибок:  6  из  94\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  38\n",
      "\tВсего ошибок:  20  из  87\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  39\n",
      "\tВсего ошибок:  11  из  87\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  40\n",
      "\tВсего ошибок:  17  из  141\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  41\n",
      "\tВсего ошибок:  3  из  51\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  42\n",
      "\tВсего ошибок:  9  из  64\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  43\n",
      "\tВсего ошибок:  20  из  116\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  44\n",
      "\tВсего ошибок:  6  из  99\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  45\n",
      "\tВсего ошибок:  16  из  84\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  46\n",
      "\tВсего ошибок:  17  из  61\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  47\n",
      "\tВсего ошибок:  8  из  77\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  48\n",
      "\tВсего ошибок:  10  из  76\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  49\n",
      "\tВсего ошибок:  5  из  82\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  50\n",
      "\tВсего ошибок:  9  из  80\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  51\n",
      "\tВсего ошибок:  56  из  206\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  52\n",
      "\tВсего ошибок:  28  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  53\n",
      "\tВсего ошибок:  24  из  102\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  54\n",
      "\tВсего ошибок:  11  из  99\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  55\n",
      "\tВсего ошибок:  6  из  39\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  56\n",
      "\tВсего ошибок:  2  из  82\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  57\n",
      "\tВсего ошибок:  4  из  34\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  58\n",
      "\tВсего ошибок:  12  из  55\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  59\n",
      "\tВсего ошибок:  24  из  103\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  60\n",
      "\tВсего ошибок:  28  из  119\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  61\n",
      "\tВсего ошибок:  16  из  82\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  62\n",
      "\tВсего ошибок:  14  из  86\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  63\n",
      "\tВсего ошибок:  10  из  100\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  64\n",
      "\tВсего ошибок:  20  из  98\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  65\n",
      "\tВсего ошибок:  11  из  99\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  66\n",
      "\tВсего ошибок:  23  из  86\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  67\n",
      "\tВсего ошибок:  21  из  88\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  68\n",
      "\tВсего ошибок:  11  из  89\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  69\n",
      "\tВсего ошибок:  11  из  54\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  70\n",
      "\tВсего ошибок:  16  из  84\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  4\n",
      "Обрабатываю ряд  71\n",
      "\tВсего ошибок:  23  из  126\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  72\n",
      "\tВсего ошибок:  18  из  68\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  75\n",
      "\tВсего ошибок:  27  из  85\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Обрабатываю ряд  76\n",
      "\tВсего ошибок:  33  из  149\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  8\n",
      "Обрабатываю ряд  78\n",
      "\tВсего ошибок:  6  из  39\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  1\n",
      "Обрабатываю ряд  86\n",
      "\tВсего ошибок:  10  из  69\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  4\n",
      "Обрабатываю ряд  88\n",
      "\tВсего ошибок:  23  из  79\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "trans_abk['mistakes'] = ''\n",
    "trans_abk['bigram_mist'] = ''\n",
    "trans_abk['new_words'] = ''\n",
    "trans_abk['mistakes_1st_type'] = ''\n",
    "trans_abk['mistakes_2nd_type'] = ''\n",
    "trans_abk['absent_words'] = ''\n",
    "\n",
    "\n",
    "for row in trans_abk.abk_transcripts.index:\n",
    "    print('Обрабатываю ряд ', row)\n",
    "    text = insert_hyphen_in_text(trans_abk.abk_transcripts[row], hyphened_words)\n",
    "    mistakes, bigrams_prob_dict, no_such_word = find_mistakes(text, cfreq, cprob)\n",
    "    true_mistakes = find_true_mistakes(mistakes, bigrams_prob_dict)\n",
    "    leven_mist = find_variation(vocab, true_mistakes)\n",
    "    \n",
    "    first_mistakes, second_mistakes, new_words = categorize_mistakes(leven_mist, true_mistakes, cprob)\n",
    "    \n",
    "    trans_abk['mistakes'][row] = ', '.join([key for key in true_mistakes])\n",
    "    trans_abk['bigram_mist'][row] = ', '.join([true_mistakes[key] for key in true_mistakes])\n",
    "    trans_abk['new_words'][row] =', '.join(new_words)\n",
    "    trans_abk['absent_words'][row] = ', '.join(no_such_word)\n",
    "    trans_abk['mistakes_1st_type'][row] = ', '.join(first_mistakes)\n",
    "    trans_abk['mistakes_2nd_type'][row] = ', '.join(second_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>abk_transcripts</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>bigram_mist</th>\n",
       "      <th>new_words</th>\n",
       "      <th>mistakes_1st_type</th>\n",
       "      <th>mistakes_2nd_type</th>\n",
       "      <th>absent_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pic-RUS_01-f_Pr-R.zip</td>\n",
       "      <td>жил был один дяденька его жены скоро должно бы...</td>\n",
       "      <td>дяденька, снова</td>\n",
       "      <td>один дяденька, осталось снова</td>\n",
       "      <td>дядька, новый</td>\n",
       "      <td>дяденька, снова</td>\n",
       "      <td>дяденька, снова</td>\n",
       "      <td>один дячка, дячка заявил</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pic-RUS_01-f_Pr-T.zip</td>\n",
       "      <td>товарищ тут с ним случилось проблема у его жен...</td>\n",
       "      <td>товарищ, какие-нибудь, присоветует, ильич, нот...</td>\n",
       "      <td>товарищ тут, какое-нибудь какие-нибудь, думаю ...</td>\n",
       "      <td>товар, посоветовать</td>\n",
       "      <td>товарищ, присоветует</td>\n",
       "      <td>товарищ, какие-нибудь, присоветует, ильич, нот...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pic-RUS_01-f_Ski-R.zip</td>\n",
       "      <td>жил был один молодой человек это молодой челов...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pic-RUS_01-f_Ski-T.zip</td>\n",
       "      <td>день жизнь одного точне увлекающейся спорту му...</td>\n",
       "      <td>точне, товарищ, человека, заряд, нажрался, мил...</td>\n",
       "      <td>одного точне, спортивный товарищ, выпиской чел...</td>\n",
       "      <td>точный, вложить</td>\n",
       "      <td>точне, ложили</td>\n",
       "      <td>точне, товарищ, человека, заряд, нажрался, мил...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pic-RUS_02-f_Pr-R.zip</td>\n",
       "      <td>однозначно был день рождения её муж решил пода...</td>\n",
       "      <td>грушой, машинку</td>\n",
       "      <td>маленькой грушой, грушой машинку</td>\n",
       "      <td>игрушка</td>\n",
       "      <td>грушой</td>\n",
       "      <td>грушой, машинку</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  audio_ID                                    abk_transcripts  \\\n",
       "35   Pic-RUS_01-f_Pr-R.zip  жил был один дяденька его жены скоро должно бы...   \n",
       "36   Pic-RUS_01-f_Pr-T.zip  товарищ тут с ним случилось проблема у его жен...   \n",
       "37  Pic-RUS_01-f_Ski-R.zip  жил был один молодой человек это молодой челов...   \n",
       "38  Pic-RUS_01-f_Ski-T.zip  день жизнь одного точне увлекающейся спорту му...   \n",
       "39   Pic-RUS_02-f_Pr-R.zip  однозначно был день рождения её муж решил пода...   \n",
       "\n",
       "                                             mistakes  \\\n",
       "35                                    дяденька, снова   \n",
       "36  товарищ, какие-нибудь, присоветует, ильич, нот...   \n",
       "37                                                      \n",
       "38  точне, товарищ, человека, заряд, нажрался, мил...   \n",
       "39                                    грушой, машинку   \n",
       "\n",
       "                                          bigram_mist            new_words  \\\n",
       "35                      один дяденька, осталось снова        дядька, новый   \n",
       "36  товарищ тут, какое-нибудь какие-нибудь, думаю ...  товар, посоветовать   \n",
       "37                                                                           \n",
       "38  одного точне, спортивный товарищ, выпиской чел...      точный, вложить   \n",
       "39                   маленькой грушой, грушой машинку              игрушка   \n",
       "\n",
       "       mistakes_1st_type                                  mistakes_2nd_type  \\\n",
       "35       дяденька, снова                                    дяденька, снова   \n",
       "36  товарищ, присоветует  товарищ, какие-нибудь, присоветует, ильич, нот...   \n",
       "37                                                                            \n",
       "38         точне, ложили  точне, товарищ, человека, заряд, нажрался, мил...   \n",
       "39                грушой                                    грушой, машинку   \n",
       "\n",
       "                absent_words  \n",
       "35  один дячка, дячка заявил  \n",
       "36                            \n",
       "37                            \n",
       "38                            \n",
       "39                            "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_abk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abk.to_excel('trans_abk_mark_ch.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка алгоритма (только марковская цепь, с учетом вводных слов и дискурсивных маркеров)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разметка ошибок и подсчет метрик precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки было размечено по 10 транскрипций для каждого транскрибатора, то есть проведем оценку качества по 20 транскрибациям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузка файлов для разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_alpha = pd.DataFrame({'word':[], 'true':0, 'pred':0})\n",
    "for ind in [35, 38, 39, 45, 46, 62, 64, 65, 66, 88]:\n",
    "    score = pd.DataFrame({'word':trans_alpha.alphacep_transcripts[ind].split()})\n",
    "    score['true'] = 0\n",
    "    score['pred'] = 0\n",
    "    score.to_excel(str(ind)+'score_alpha_mark_ch.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_abk = pd.DataFrame({'word':[], 'true':0, 'pred':0})\n",
    "for ind in [35, 38, 39, 45, 46, 62, 64, 65, 66, 88]:\n",
    "    score = pd.DataFrame({'word':trans_abk.abk_transcripts[ind].split()})\n",
    "    score['true'] = 0\n",
    "    score['pred'] = 0\n",
    "    score.to_excel(str(ind)+'score_abk_mark_ch.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка размеченных файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_alpha = ['35score_alpha_mark_ch.xlsx','38score_alpha_mark_ch.xlsx','39score_alpha_mark_ch.xlsx','45score_alpha_mark_ch.xlsx','46score_alpha_mark_ch.xlsx', '62score_alpha_mark_ch.xlsx','64score_alpha_mark_ch.xlsx','65score_alpha_mark_ch.xlsx','66score_alpha_mark_ch.xlsx','88score_alpha_mark_ch.xlsx']\n",
    "files_abk = ['35score_abk_mark_ch.xlsx','38score_abk_mark_ch.xlsx','39score_abk_mark_ch.xlsx','45score_abk_mark_ch.xlsx','46score_abk_mark_ch.xlsx', '62score_abk_mark_ch.xlsx','64score_abk_mark_ch.xlsx','65score_abk_mark_ch.xlsx','66score_abk_mark_ch.xlsx','88score_abk_mark_ch.xlsx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формирование значений y_true для транскрибаций alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_alpha = []\n",
    "y_pred_alpha = []\n",
    "for file in files_alpha:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_true_alpha+=y_true \n",
    "    y_pred = list(df.pred)\n",
    "    y_pred_alpha += y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формирование значений y_true для транскрибаций abk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_abk = []\n",
    "y_pred_abk = []\n",
    "for file in files_abk:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_true_abk+=y_true \n",
    "    y_pred = list(df.pred)\n",
    "    y_pred_abk += y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подсчет метрик для всех транскрибаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all alphacep transcriptions:\n",
      "\tPrecision: 0.6022\n",
      "\tRecall: 0.3889\n",
      "\tF1: 0.4726\n",
      "\tAccuracy: 0.8751\n"
     ]
    }
   ],
   "source": [
    "print('For all alphacep transcriptions:')\n",
    "print('\\tPrecision: {:0.4f}'.format(precision_score(y_true_alpha, y_pred_alpha)))\n",
    "print('\\tRecall: {:0.4f}'.format(recall_score(y_true_alpha, y_pred_alpha)))\n",
    "print('\\tF1: {:0.4f}'.format(f1_score(y_true_alpha, y_pred_alpha)))\n",
    "print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true_alpha, y_pred_alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all ABK transcriptions:\n",
      "\tPrecision: 0.4493\n",
      "\tRecall: 0.2138\n",
      "\tF1: 0.2897\n",
      "\tAccuracy: 0.8433\n"
     ]
    }
   ],
   "source": [
    "print('For all ABK transcriptions:')\n",
    "print('\\tPrecision: {:0.4f}'.format(precision_score(y_true_abk, y_pred_abk)))\n",
    "print('\\tRecall: {:0.4f}'.format(recall_score(y_true_abk, y_pred_abk)))\n",
    "print('\\tF1: {:0.4f}'.format(f1_score(y_true_abk, y_pred_abk)))\n",
    "print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true_abk, y_pred_abk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подсчет метрик отдельно для каждой транскрибации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For file: 35score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.6364\n",
      "\tRecall: 0.4375\n",
      "\tF1: 0.5185\n",
      "\tAccuracy: 0.9091\n",
      "For file: 38score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.6667\n",
      "\tRecall: 0.8571\n",
      "\tF1: 0.7500\n",
      "\tAccuracy: 0.9529\n",
      "For file: 39score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.5000\n",
      "\tF1: 0.6667\n",
      "\tAccuracy: 0.9630\n",
      "For file: 45score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.8000\n",
      "\tRecall: 0.6667\n",
      "\tF1: 0.7273\n",
      "\tAccuracy: 0.9651\n",
      "For file: 46score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.2500\n",
      "\tRecall: 0.1429\n",
      "\tF1: 0.1818\n",
      "\tAccuracy: 0.8714\n",
      "For file: 62score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.5000\n",
      "\tRecall: 0.2222\n",
      "\tF1: 0.3077\n",
      "\tAccuracy: 0.9143\n",
      "For file: 64score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.4000\n",
      "\tRecall: 0.3158\n",
      "\tF1: 0.3529\n",
      "\tAccuracy: 0.7982\n",
      "For file: 65score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.8750\n",
      "\tRecall: 0.2188\n",
      "\tF1: 0.3500\n",
      "\tAccuracy: 0.7778\n",
      "For file: 66score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.5000\n",
      "\tRecall: 0.3077\n",
      "\tF1: 0.3810\n",
      "\tAccuracy: 0.8687\n",
      "For file: 88score_alpha_mark_ch.xlsx\n",
      "\tPrecision: 0.6154\n",
      "\tRecall: 0.5517\n",
      "\tF1: 0.5818\n",
      "\tAccuracy: 0.7830\n"
     ]
    }
   ],
   "source": [
    "for file in files_alpha:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_pred = list(df.pred)\n",
    "    print('For file:', file)\n",
    "    print('\\tPrecision: {:0.4f}'.format(precision_score(y_true, y_pred)))\n",
    "    print('\\tRecall: {:0.4f}'.format(recall_score(y_true, y_pred)))\n",
    "    print('\\tF1: {:0.4f}'.format(f1_score(y_true, y_pred)))\n",
    "    print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For file: 35score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.6667\n",
      "\tRecall: 0.1429\n",
      "\tF1: 0.2353\n",
      "\tAccuracy: 0.9167\n",
      "For file: 38score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.4444\n",
      "\tRecall: 0.6667\n",
      "\tF1: 0.5333\n",
      "\tAccuracy: 0.9231\n",
      "For file: 39score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.5000\n",
      "\tRecall: 0.0667\n",
      "\tF1: 0.1176\n",
      "\tAccuracy: 0.8333\n",
      "For file: 45score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.7500\n",
      "\tRecall: 0.3750\n",
      "\tF1: 0.5000\n",
      "\tAccuracy: 0.9310\n",
      "For file: 46score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.2857\n",
      "\tRecall: 0.2500\n",
      "\tF1: 0.2667\n",
      "\tAccuracy: 0.8281\n",
      "For file: 62score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.0000\n",
      "\tRecall: 0.0000\n",
      "\tF1: 0.0000\n",
      "\tAccuracy: 0.9029\n",
      "For file: 64score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.3000\n",
      "\tRecall: 0.2143\n",
      "\tF1: 0.2500\n",
      "\tAccuracy: 0.8235\n",
      "For file: 65score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.7500\n",
      "\tRecall: 0.1111\n",
      "\tF1: 0.1935\n",
      "\tAccuracy: 0.7596\n",
      "For file: 66score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.5455\n",
      "\tRecall: 0.3158\n",
      "\tF1: 0.4000\n",
      "\tAccuracy: 0.8022\n",
      "For file: 88score_abk_mark_ch.xlsx\n",
      "\tPrecision: 0.4375\n",
      "\tRecall: 0.2593\n",
      "\tF1: 0.3256\n",
      "\tAccuracy: 0.6463\n"
     ]
    }
   ],
   "source": [
    "for file in files_abk:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_pred = list(df.pred)\n",
    "    print('For file:', file)\n",
    "    print('\\tPrecision: {:0.4f}'.format(precision_score(y_true, y_pred)))\n",
    "    print('\\tRecall: {:0.4f}'.format(recall_score(y_true, y_pred)))\n",
    "    print('\\tF1: {:0.4f}'.format(f1_score(y_true, y_pred)))\n",
    "    print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробуем устранить количество ложно распознанных ошибок с помощью векторной модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка готовой векторной модели с сайта RusVectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зазгрузим модель tayga-func_upos_skipgram_300_5_2019, обученную на корпусе Taiga c функциональными словами.\n",
    "\n",
    "Ссылка на модель находится [здесь]('http://vectors.nlpl.eu/repository/11/186.zip'): \n",
    "\n",
    "**Характеристики модели:**\n",
    "\n",
    "Дата создания  - январь 2019\n",
    "\n",
    "Размер обучающего корпуса - почти 5 млрд слов \n",
    "\n",
    "Объем словаря - 249 946 слов\n",
    "\n",
    "Алгоритм обучения - Continuous Skipgram\n",
    "\n",
    "Размер окна - 5\n",
    "\n",
    "Размерность вектора - 300\n",
    "\n",
    "Набор частеречных тэгов - Universal Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "model_url = 'http://vectors.nlpl.eu/repository/11/186.zip' #ссылка на модель\n",
    "m = wget.download(model_url)\n",
    "model_file = model_url.split('/')[-1]\n",
    "with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "    stream = archive.open('model.bin')\n",
    "    w2v_tayga_model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшой тест модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['дяденька_NOUN', 'зимний_ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тетенька_NOUN 0.8230295777320862\n",
      "_NOUN\n",
      "\n",
      "\n",
      "дядечка_NOUN 0.8126401305198669\n",
      "_NOUN\n",
      "\n",
      "\n",
      "дядька_NOUN 0.6924134492874146\n",
      "_NOUN\n",
      "\n",
      "\n",
      "дяденька_ADJ 0.6899006962776184\n",
      "_ADJ\n",
      "\n",
      "\n",
      "тетенька_ADJ 0.6767088174819946\n",
      "_ADJ\n",
      "\n",
      "\n",
      "тетечка_NOUN 0.654828667640686\n",
      "_NOUN\n",
      "\n",
      "\n",
      "дяденька_PROPN 0.6515356302261353\n",
      "_PROPN\n",
      "\n",
      "\n",
      "старичок_NOUN 0.6482418179512024\n",
      "_NOUN\n",
      "\n",
      "\n",
      "тетенек_NOUN 0.6351189613342285\n",
      "_NOUN\n",
      "\n",
      "\n",
      "мужичок_NOUN 0.627760648727417\n",
      "_NOUN\n",
      "\n",
      "\n",
      "зимний_NOUN 0.8504959344863892\n",
      "_NOUN\n",
      "\n",
      "\n",
      "осенний_ADJ 0.730405330657959\n",
      "_ADJ\n",
      "\n",
      "\n",
      "летний_ADJ 0.7238248586654663\n",
      "_ADJ\n",
      "\n",
      "\n",
      "весенний_ADJ 0.6703113317489624\n",
      "_ADJ\n",
      "\n",
      "\n",
      "зимний_PRON 0.6563525795936584\n",
      "_PRON\n",
      "\n",
      "\n",
      "зима_NOUN 0.6446696519851685\n",
      "_NOUN\n",
      "\n",
      "\n",
      "декабрьский_ADJ 0.6300435066223145\n",
      "_ADJ\n",
      "\n",
      "\n",
      "январский_ADJ 0.6299617290496826\n",
      "_ADJ\n",
      "\n",
      "\n",
      "предзимний_ADJ 0.6147400140762329\n",
      "_ADJ\n",
      "\n",
      "\n",
      "зима_PROPN 0.613741397857666\n",
      "_PROPN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word in w2v_tayga_model: #проверяем, есть ли слово в модели\n",
    "        for i in w2v_tayga_model.most_similar(positive=[word], topn=10): # выдаем 10 ближайших соседей слова:\n",
    "            if re.search(r'_[A-Z]{3,5}', i[0]) is not None: \n",
    "                pos_tag = re.search(r'_[A-Z]{1,5}', i[0])[0]\n",
    "                print(i[0], i[1]) # слово + коэффициент косинусной близости\n",
    "                print(pos_tag)\n",
    "                print('\\n')\n",
    "    else:\n",
    "        print(word + ' is not present in the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно будет использовать тот же набор частеречных тэгов в тестовом корпусе, что используется и в обучающем, то есть тэги Universal Dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько слов, почему мы не выбросили частеречные тэги из предобученной векторной модели:\n",
    "    1. Отсеиваем сомнительные случаи (незнакомые слова), скажем слова с тэгами _X.\n",
    "    2. Вычисляем вероятность в нашей марковской цепи только для тех семантических ассоциатов, у которых частеречный тэг совпадает с тэгом у слова-ошибки в нашей биграмме\n",
    "    3. Исключаем частеречную омонимию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание словаря для конвертации частеречных тэгов \n",
    "[Pymorphy2](http://opencorpora.org/dict.php?act=gram&order=priority) \n",
    "## в тэги \n",
    "[Unversal POS](https://universaldependencies.org/u/pos/all.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_Pymorphy_UPos = {\n",
    "'ADJF': 'ADJ',\n",
    "'ADJS': 'ADJ',\n",
    "'ADVB': 'ADV',\n",
    "'Apro': 'DET',\n",
    "'COMP': 'ADV',  # может быть и прилагательным, недостаточно информации о тэге в opencorpora\n",
    "'CONJ': 'CONJ',\n",
    "'GRND': 'VERB',\n",
    "'INFN': 'VERB',\n",
    "'INTJ': 'INTJ',\n",
    "'NOUN': 'NOUN',\n",
    "'NPRO': 'PRON',\n",
    "'NUMR': 'NUM',\n",
    "'NUMB': 'NUM',\n",
    "'PART': 'PRCL',\n",
    "'PNCT': 'PUNCT',\n",
    "'PRCL': 'PART',\n",
    "'PREP': 'ADP',\n",
    "'PRTF': 'VERB',\n",
    "'PRTS': 'VERB',\n",
    "'VERB': 'VERB'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение словаря для конвертации частеречных тэгов\n",
    "save_mapping = open(\"map_pymorphy2_UPos.pickle\" , \"wb\" )\n",
    "pickle.dump(mapping_Pymorphy_UPos, save_mapping)\n",
    "save_mapping .close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка]('https://github.com/smekur/Spoken_Corpora_with_Kaldi/blob/master/mistakes_search/others/map_pymorphy2_UPos.pickle') для скачивания словаря конвертации тэгов выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объявление функций для работы с новым алгоритмом на основе векторной модели Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция осуществляет частеречную разметку в виде Universal POS-tags у предполагаемого слова-ошибки. \n",
    "(Предобработка необходима для работы с предобученной моделью от RusVectores.)\n",
    "\n",
    "Аргументы:\n",
    "    true_mistakes - словарь вида: {`слово-ошибка`: `биграмма-кандидат`}\n",
    "    mapping - словарь-таблица для конвертации тэгов частей речи из одного формата в другой.  \n",
    "Вывод:\n",
    "    tagged_true_mistakes - словарь вида: {`слово-ошибка_с частеречным тэгом`: `биграма-кандидат`}\n",
    "'''\n",
    "\n",
    "def insert_pos_tags(true_mistakes, mapping):\n",
    "    tagged_true_mistakes = {}\n",
    "    for mistake in true_mistakes: #{'дяденька': 'один дяденька'}\n",
    "        #print('Итерируемся по словарю ошибок. Берем ключ словаря(ошибку):', mistake, '\\n')\n",
    "        mistake_analized = morph.parse(mistake) # морф анализ\n",
    "        #print('Делаем морф анализ. ключа. Результат:', mistake_analized, '\\n')\n",
    "        mistake_lemma = mistake_analized[0].normal_form #извлекаем лемму\n",
    "        #print('Печатаем лемму ключа:', mistake_lemma, '\\n')\n",
    "        pos = mistake_analized[0].tag.POS #извлекаем частеречный тэг\n",
    "        #print('Вычисляем частеречный тэг ключа:', pos, '\\n')\n",
    "        if pos in mapping: #если частеречный тэг есть в словаре конвертации тэгов\n",
    "            tagged_lemma = mistake_lemma + '_' + mapping[pos] #получаем лемму с частеречным тэгом: lemma_POS-tag\n",
    "            #print('Тэг в мэппинге. Печатаю лемму ключа с тэгом:', tagged_lemma, '\\n')\n",
    "        else:\n",
    "            tagged_lemma = mistake_lemma + '_X' # на случай, если попадется тэг, которого нет в словаре\n",
    "            #print('Нет тэга в мэппинге. Печатаю лемму ключа с тэгом X:', tagged_lemma, '\\n')\n",
    "        value = true_mistakes.get(mistake) \n",
    "        #print('Значение для ключа в новом словаре:', value, '\\n')\n",
    "        tagged_true_mistakes[tagged_lemma] = value\n",
    "        #print('Пополняем новый словарь. Добавляем лемму с тэгом в виде ключа', tagged_lemma,  'и его значение:', value)\n",
    "    \n",
    "    return tagged_true_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для проверки слов-ошибок с помощью косинусной близости и модели word2vec: \n",
    "Проверяем с помощью косинусной близости, есть ли такое близкое слову-ошибке слово, которое образует биграмму, вероятность у которой в обученной марковской цепи выше нуля.\n",
    "Если из 10 ближайших соседей такое слово находится, то мы не считаем слово-ошибку в биграмме истинной ошибкой. \n",
    "\n",
    "Аргументы:\n",
    "    tagged_true_mistakes - словарь вида: {`слово-ошибка_с частеречным тэгом`: `биграмма со словом-ошибкой`}.\n",
    "    vec_model - векторная модель\n",
    "    prob_threshold - порог для установления вероятности слова-ошибки в биграмме в марковской цепи - INT (по умолчанию равен 0.0008, значение выставлено по результатам анализа ошибок)\n",
    "    cos_similarity_threshold - порог для установления косинусной близости семантического ассоциата к слову-ошибке - INT (по умолчанию равен 0.69, значение выставлено по результатам анализа ошибок)\n",
    "\n",
    "Вывод:\n",
    "    not_mistakes - список отфильтрованных ошибок: такие слова, которые считались ошибками в марковской цепи, а после применения алгоритма с косинусной близостью были отфильтрованы\n",
    "    no_UDPos_tags - список слов, у которых частеречный тэг не имеет соответствия в наборе тэгов UDPos\n",
    "    filtered_true_mistakes - словарь истинных ошибок после отработки алгоритма  с косинусной близостью: ключ без частеречного тэга и в виде исходной словоформы текста\n",
    "'''\n",
    "\n",
    "def filter_mistakes_with_cos_similarity(tagged_true_mistakes, vec_model, model_prob, true_mistakes, prob_threshold = 0.0008, cos_similarity_threshold = 0.69):    \n",
    "    no_UDPos_tags = [] \n",
    "    filtered_true_mistakes = {} \n",
    "    not_mistakes = []\n",
    "\n",
    "    for key in tagged_true_mistakes.copy():\n",
    "    #print('Печатаю ключ в исходном словаре:', key)\n",
    "        if key in vec_model: #проверяем, есть ли слово в модели\n",
    "            print('Ключ есть в модели word2vec')\n",
    "            if re.search(r'_[A-Z]{3,5}', key) is not None: #проверяем, что есть частеречный тэг не X\n",
    "                key_tag = re.search(r'_[A-Z]{3,5}', key)[0] #запоминаем частеречный тэг у слова-ошибки\n",
    "                key_without_tag = re.sub(r'_[A-Z]{3,5}','', key) #запоминаем слово-ошибку без частеречного тэга\n",
    "                #print('Печатаю частеречный тэг ключа:', key_tag)\n",
    "                #print('Печатаю ключ без тэга:', key_without_tag)\n",
    "                value = tagged_true_mistakes.get(key) #берем значение ключа\n",
    "                #print('Значение нашего ключа:', value)\n",
    "                big = value.split() #разбиваем на части нашу строку из двух слов\n",
    "                big = [morph.normal_forms(token)[0] for token in big] #лемматизируем каждое слово в биграмме \n",
    "            else: \n",
    "                print('У слова-ошибки обнаружен частеречный тэг, который отсутствует в UDPos') \n",
    "                no_UDPos_tags.append(key) #если тэг _X, то заносим такие слова в отдельный список\n",
    "            for candidate in vec_model.most_similar(positive=[key], topn=10): #смотрим 10 ближайших соседей для слова-ошибки:\n",
    "                #print('Итерируемся по соседям ключа. Берем соседа:', candidate)\n",
    "                if re.search(r'_[A-Z]{3,5}', candidate[0]) is not None: #не рассматриваем кандидатов с тэгами _X\n",
    "                    candidate_tag = re.search(r'_[A-Z]{3,5}', candidate[0])[0] #запоминаем ключ кандидата \n",
    "                if re.fullmatch(r'[а-я]+_[A-Z]{3,5}',candidate[0]) is not None and candidate[0]!= key and candidate_tag == key_tag: \n",
    "                #берем только кандидатов, которые отвечают формату: слово_POStag; не совпадают с нашим ключом и частеречный тэг у которого совпадает с тэгом у нашего ключа\n",
    "                    #print('Кандидат отвечает формату:', candidate[0])\n",
    "                    #print('Тэг кандидата:', candidate_tag)\n",
    "                    candidate_without_tag = re.sub(r'_[A-Z]{3,5}','', candidate[0]) #убираем частеречный тэг у подходящего кандитата\n",
    "                    #print('Кандидат без тэга:', candidate_without_tag)\n",
    "                \n",
    "                    if key_without_tag == big[1]:\n",
    "                        #print(\"Ключ-ошибка\", key_without_tag, \"является вторым словом в биграме:\", big, 'Подставляю кандидата', candidate_without_tag, 'в .prob')\n",
    "                        \n",
    "                        #если кос близость >= 0.69, то пропускаем сем ассоциат слову-ошибке с любой положительной вероятностью в марковской цепи\n",
    "                        #если кос близость <= 0.69, то пропускаем только с вероятностью >=0.0008\n",
    "                        \n",
    "                        if model_prob[big[0]].prob(candidate_without_tag)<=0:\n",
    "                            #print('Кандидат',candidate_without_tag, 'не образует вероятностную биграмму')\n",
    "                            continue\n",
    "                            \n",
    "                        elif 0 < model_prob[big[0]].prob(candidate_without_tag)<=prob_threshold and candidate[1] <= cos_similarity_threshold:\n",
    "                            #print('Кандидат',candidate_without_tag, 'не образует вероятностную биграмму из-за не прохождения порога cos_similarity_threshold')\n",
    "                            continue\n",
    "                            \n",
    "                        else: #если мы поймали вероятностную биграмму \n",
    "                            print('Слово', key, 'не ошибка')\n",
    "                            not_mistakes.append(key)\n",
    "                            del tagged_true_mistakes[key] #удаляем ключ со словом ошибкой из словаря\n",
    "                            break\n",
    "                        \n",
    "                    else:\n",
    "                        #print(\"Ключ-ошибка\", key_without_tag, \"является первым словом в биграме:\", big)\n",
    "                        if model_prob[candidate_without_tag].prob(big[1])<=0:\n",
    "                            #print('Кандидат',candidate_without_tag, 'не образует вероятностную биграмму')\n",
    "                            continue\n",
    "                            \n",
    "                        elif 0 < model_prob[candidate_without_tag].prob(big[1])<=prob_threshold and candidate[1] <= cos_similarity_threshold:\n",
    "                            #print('Кандидат',candidate_without_tag, 'не образует вероятностную биграмму из-за не прохождения порога cos_similarity_threshold')\n",
    "                            continue\n",
    "                            \n",
    "                        else:\n",
    "                            #print('Слово', key, 'не ошибка')\n",
    "                            not_mistakes.append(key)\n",
    "                            del tagged_true_mistakes[key]\n",
    "                            break\n",
    "    \n",
    "    filtered_true_mistakes = {} #создаем список ошибок после фильтрации алгоритмом с помощью векторной модели\n",
    "    \n",
    "    for key in true_mistakes:\n",
    "        if true_mistakes.get(key) in tagged_true_mistakes.values():\n",
    "            filtered_true_mistakes[key] = true_mistakes.get(key) \n",
    "                            \n",
    "    return filtered_true_mistakes, not_mistakes, no_UDPos_tags        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с транскрибациями (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Снова загрузим наши транскрибации (тестовый корпус):\n",
    "trans = pd.read_excel('all_transcripts.xlsx')\n",
    "trans_alpha = trans.loc[\n",
    "       (trans.audio_ID.str.contains('Sib')|trans.audio_ID.str.contains('Pic'))&trans.alphacep_transcripts.notnull(),\n",
    "       ['audio_ID','alphacep_transcripts']\n",
    "    ]\n",
    "trans_abk = trans.loc[\n",
    "       (trans.audio_ID.str.contains('Sib')|trans.audio_ID.str.contains('Pic'))&trans.abk_transcripts.notnull(),\n",
    "       ['audio_ID','abk_transcripts']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус транскрибатора Alphacep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "Обрабатываю ряд  35\n",
      "\tВсего ошибок:  24  из  137\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово дяденька_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  38\n",
      "\tВсего ошибок:  15  из  81\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  3\n",
      "Ключ есть в модели word2vec\n",
      "Слово хотеться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  39\n",
      "\tВсего ошибок:  12  из  78\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово посылать_VERB не ошибка\n",
      "Обрабатываю ряд  42\n",
      "\tВсего ошибок:  5  из  65\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  45\n",
      "\tВсего ошибок:  19  из  83\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  46\n",
      "\tВсего ошибок:  16  из  68\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово зимний_ADJ не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  52\n",
      "\tВсего ошибок:  31  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  54\n",
      "\tВсего ошибок:  15  из  106\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  55\n",
      "\tВсего ошибок:  5  из  39\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  58\n",
      "\tВсего ошибок:  11  из  58\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Слово дядечка_NOUN не ошибка\n",
      "Обрабатываю ряд  59\n",
      "\tВсего ошибок:  27  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово ледяной_ADJ не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  60\n",
      "\tВсего ошибок:  29  из  129\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово почему-то_ADV не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово поворачиваться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  62\n",
      "\tВсего ошибок:  16  из  94\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  64\n",
      "\tВсего ошибок:  30  из  105\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово заодно_ADV не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово отказаться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  65\n",
      "\tВсего ошибок:  22  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  66\n",
      "\tВсего ошибок:  20  из  96\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово покататься_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  73\n",
      "\tВсего ошибок:  54  из  176\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово поэт_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  77\n",
      "\tВсего ошибок:  110  из  322\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово разбудить_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово фужер_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово покушать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово девяносто_NUM не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово прикольный_ADJ не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  79\n",
      "\tВсего ошибок:  93  из  285\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  7\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово девяносто_NUM не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово ярко_ADV не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово свитка_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово копна_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово зад_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово принц_NOUN не ошибка\n",
      "Обрабатываю ряд  84\n",
      "\tВсего ошибок:  61  из  248\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  14\n",
      "Ключ есть в модели word2vec\n",
      "Слово кибер_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово таксист_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  85\n",
      "\tВсего ошибок:  56  из  175\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово халиф_NOUN не ошибка\n",
      "Обрабатываю ряд  87\n",
      "\tВсего ошибок:  101  из  443\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  26\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово мрак_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово увидеть_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово тронуть_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово переправлять_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  88\n",
      "\tВсего ошибок:  36  из  105\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  8\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово леспромхоз_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  89\n",
      "\tВсего ошибок:  91  из  369\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  14\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово штанец_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово ширина_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово она_PRON не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "trans_alpha['mistakes'] = ''\n",
    "trans_alpha['bigram_mist'] = ''\n",
    "trans_alpha['new_words'] = ''\n",
    "trans_alpha['mistakes_1st_type'] = ''\n",
    "trans_alpha['mistakes_2nd_type'] = ''\n",
    "trans_alpha['absent_words'] = ''\n",
    "\n",
    "trans_alpha['w2v_mistakes'] = ''\n",
    "trans_alpha['w2v_bigram_mist'] = ''\n",
    "trans_alpha['w2v_new_words'] = ''\n",
    "trans_alpha['w2v_mistakes_1st_type'] = ''\n",
    "trans_alpha['w2v_mistakes_2nd_type'] = ''\n",
    "\n",
    "\n",
    "for row in trans_alpha.alphacep_transcripts.index:\n",
    "    print('Обрабатываю ряд ', row)\n",
    "    text = insert_hyphen_in_text(trans_alpha.alphacep_transcripts[row], hyphened_words)\n",
    "    mistakes, bigrams_prob_dict, no_such_word = find_mistakes(text, cfreq, cprob)\n",
    "    true_mistakes = find_true_mistakes(mistakes, bigrams_prob_dict)\n",
    "    leven_mist = find_variation(vocab, true_mistakes)\n",
    "    \n",
    "    first_mistakes, second_mistakes, new_words = categorize_mistakes(leven_mist, true_mistakes, cprob)\n",
    "    \n",
    "    tagged_true_mistakes = insert_pos_tags(true_mistakes, mapping_Pymorphy_UPos)\n",
    "    filtered_true_mistakes, not_mistakes, no_UDPos_tags  = filter_mistakes_with_cos_similarity(tagged_true_mistakes, w2v_tayga_model, cprob, true_mistakes)\n",
    "    w2v_leven_mist = find_variation(vocab, filtered_true_mistakes)\n",
    "    \n",
    "    \n",
    "    w2v_first_mistakes, w2v_second_mistakes, w2v_new_words = categorize_mistakes(w2v_leven_mist, filtered_true_mistakes, cprob)\n",
    "    \n",
    "    trans_alpha['mistakes'][row] = ', '.join([key for key in true_mistakes])\n",
    "    trans_alpha['bigram_mist'][row] = ', '.join([true_mistakes[key] for key in true_mistakes])\n",
    "    trans_alpha['new_words'][row] =', '.join(new_words)\n",
    "    trans_alpha['absent_words'][row] = ', '.join(no_such_word)\n",
    "    trans_alpha['mistakes_1st_type'][row] = ', '.join(first_mistakes)\n",
    "    trans_alpha['mistakes_2nd_type'][row] = ', '.join(second_mistakes)\n",
    "    \n",
    "    trans_alpha['w2v_mistakes'][row] = ', '.join([key for key in filtered_true_mistakes])\n",
    "    trans_alpha['w2v_bigram_mist'][row] = ', '.join([filtered_true_mistakes[key] for key in filtered_true_mistakes])\n",
    "    trans_alpha['w2v_new_words'][row] =', '.join(w2v_new_words)\n",
    "    trans_alpha['w2v_mistakes_1st_type'][row] = ', '.join(w2v_first_mistakes)\n",
    "    trans_alpha['w2v_mistakes_2nd_type'][row] = ', '.join(w2v_second_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>alphacep_transcripts</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>bigram_mist</th>\n",
       "      <th>new_words</th>\n",
       "      <th>mistakes_1st_type</th>\n",
       "      <th>mistakes_2nd_type</th>\n",
       "      <th>absent_words</th>\n",
       "      <th>w2v_mistakes</th>\n",
       "      <th>w2v_bigram_mist</th>\n",
       "      <th>w2v_new_words</th>\n",
       "      <th>w2v_mistakes_1st_type</th>\n",
       "      <th>w2v_mistakes_2nd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pic-RUS_01-f_Pr-R.zip</td>\n",
       "      <td>жилбыл один дяденька по его жены скоро должно ...</td>\n",
       "      <td>дяденька, плот, ночного, посол, салон, наставь...</td>\n",
       "      <td>один дяденька, случится плот, дяденька ночного...</td>\n",
       "      <td>дядька, ставить</td>\n",
       "      <td>дяденька, наставь</td>\n",
       "      <td>дяденька, плот, ночного, посол, салон, наставь...</td>\n",
       "      <td>посол варт, варт салон</td>\n",
       "      <td>плот, ночного, посол, наставь, дядечка, носок,...</td>\n",
       "      <td>случится плот, дяденька ночного, глупости посо...</td>\n",
       "      <td>ставить</td>\n",
       "      <td>наставь</td>\n",
       "      <td>плот, ночного, посол, наставь, дядечка, носок,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pic-RUS_01-f_Ski-T.zip</td>\n",
       "      <td>генин жизни одного очень увлекающийся спортом ...</td>\n",
       "      <td>хочется, партийный, товарищ, тоесть, природу, ...</td>\n",
       "      <td>катался хочется, хочется партийный, партийный ...</td>\n",
       "      <td>хотеть</td>\n",
       "      <td>хочется</td>\n",
       "      <td>хочется, партийный, товарищ, тоесть, природу, ...</td>\n",
       "      <td>генин жизни, и норг, норг тоесть</td>\n",
       "      <td>партийный, товарищ, тоесть, природу, ходит, не...</td>\n",
       "      <td>хочется партийный, партийный товарищ, тоесть п...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>партийный, товарищ, тоесть, природу, ходит, не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pic-RUS_02-f_Pr-R.zip</td>\n",
       "      <td>однозначным был день рождения мышь решил подар...</td>\n",
       "      <td>однозначным, мышь, посылала</td>\n",
       "      <td>однозначным был, рождения мышь, в посылала</td>\n",
       "      <td>однозначно, подослать</td>\n",
       "      <td>однозначным, посылала</td>\n",
       "      <td>однозначным, мышь, посылала</td>\n",
       "      <td></td>\n",
       "      <td>мышь</td>\n",
       "      <td>рождения мышь</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>мышь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pic-RUS_02-f_Ski-T.zip</td>\n",
       "      <td>этот человек встал рано утром позавтракал а по...</td>\n",
       "      <td>наложены, божественного</td>\n",
       "      <td>отправился наложены, голову божественного</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>наложены, божественного</td>\n",
       "      <td></td>\n",
       "      <td>наложены, божественного</td>\n",
       "      <td>отправился наложены, голову божественного</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>наложены, божественного</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Pic-RUS_03-m_Ski-R.zip</td>\n",
       "      <td>знакомым мне здесь рассказали одну смешную и п...</td>\n",
       "      <td>нагорных, доскачет, поехать, наложением, слышь</td>\n",
       "      <td>лыжах нагорных, дороге доскачет, позвать поеха...</td>\n",
       "      <td>горный</td>\n",
       "      <td>нагорных</td>\n",
       "      <td>нагорных, доскачет, поехать, наложением, слышь</td>\n",
       "      <td></td>\n",
       "      <td>нагорных, доскачет, поехать, наложением, слышь</td>\n",
       "      <td>лыжах нагорных, дороге доскачет, позвать поеха...</td>\n",
       "      <td>горный</td>\n",
       "      <td>нагорных</td>\n",
       "      <td>нагорных, доскачет, поехать, наложением, слышь</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  audio_ID                               alphacep_transcripts  \\\n",
       "35   Pic-RUS_01-f_Pr-R.zip  жилбыл один дяденька по его жены скоро должно ...   \n",
       "38  Pic-RUS_01-f_Ski-T.zip  генин жизни одного очень увлекающийся спортом ...   \n",
       "39   Pic-RUS_02-f_Pr-R.zip  однозначным был день рождения мышь решил подар...   \n",
       "42  Pic-RUS_02-f_Ski-T.zip  этот человек встал рано утром позавтракал а по...   \n",
       "45  Pic-RUS_03-m_Ski-R.zip  знакомым мне здесь рассказали одну смешную и п...   \n",
       "\n",
       "                                             mistakes  \\\n",
       "35  дяденька, плот, ночного, посол, салон, наставь...   \n",
       "38  хочется, партийный, товарищ, тоесть, природу, ...   \n",
       "39                        однозначным, мышь, посылала   \n",
       "42                            наложены, божественного   \n",
       "45     нагорных, доскачет, поехать, наложением, слышь   \n",
       "\n",
       "                                          bigram_mist              new_words  \\\n",
       "35  один дяденька, случится плот, дяденька ночного...        дядька, ставить   \n",
       "38  катался хочется, хочется партийный, партийный ...                 хотеть   \n",
       "39         однозначным был, рождения мышь, в посылала  однозначно, подослать   \n",
       "42          отправился наложены, голову божественного                          \n",
       "45  лыжах нагорных, дороге доскачет, позвать поеха...                 горный   \n",
       "\n",
       "        mistakes_1st_type                                  mistakes_2nd_type  \\\n",
       "35      дяденька, наставь  дяденька, плот, ночного, посол, салон, наставь...   \n",
       "38                хочется  хочется, партийный, товарищ, тоесть, природу, ...   \n",
       "39  однозначным, посылала                        однозначным, мышь, посылала   \n",
       "42                                                   наложены, божественного   \n",
       "45               нагорных     нагорных, доскачет, поехать, наложением, слышь   \n",
       "\n",
       "                        absent_words  \\\n",
       "35            посол варт, варт салон   \n",
       "38  генин жизни, и норг, норг тоесть   \n",
       "39                                     \n",
       "42                                     \n",
       "45                                     \n",
       "\n",
       "                                         w2v_mistakes  \\\n",
       "35  плот, ночного, посол, наставь, дядечка, носок,...   \n",
       "38  партийный, товарищ, тоесть, природу, ходит, не...   \n",
       "39                                               мышь   \n",
       "42                            наложены, божественного   \n",
       "45     нагорных, доскачет, поехать, наложением, слышь   \n",
       "\n",
       "                                      w2v_bigram_mist w2v_new_words  \\\n",
       "35  случится плот, дяденька ночного, глупости посо...       ставить   \n",
       "38  хочется партийный, партийный товарищ, тоесть п...                 \n",
       "39                                      рождения мышь                 \n",
       "42          отправился наложены, голову божественного                 \n",
       "45  лыжах нагорных, дороге доскачет, позвать поеха...        горный   \n",
       "\n",
       "   w2v_mistakes_1st_type                              w2v_mistakes_2nd_type  \n",
       "35               наставь  плот, ночного, посол, наставь, дядечка, носок,...  \n",
       "38                        партийный, товарищ, тоесть, природу, ходит, не...  \n",
       "39                                                                     мышь  \n",
       "42                                                  наложены, божественного  \n",
       "45              нагорных     нагорных, доскачет, поехать, наложением, слышь  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_alpha.to_excel('trans_alpha_w2v.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>alphacep_transcripts</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>bigram_mist</th>\n",
       "      <th>new_words</th>\n",
       "      <th>mistakes_1st_type</th>\n",
       "      <th>mistakes_2nd_type</th>\n",
       "      <th>absent_words</th>\n",
       "      <th>w2v_mistakes</th>\n",
       "      <th>w2v_bigram_mist</th>\n",
       "      <th>w2v_new_words</th>\n",
       "      <th>w2v_mistakes_1st_type</th>\n",
       "      <th>w2v_mistakes_2nd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Sib_12-f</td>\n",
       "      <td>так оно и какуюнибудь игру сработает о чем не ...</td>\n",
       "      <td>киберов, паники, пайки, пупком, спектры, рубан...</td>\n",
       "      <td>не киберов, собирали паники, собирали пайки, м...</td>\n",
       "      <td>кибермэн, сектор, амулет, собрать, дом, побежать</td>\n",
       "      <td>киберов, спектры, гамлета, собирать, домовым, ...</td>\n",
       "      <td>киберов, паники, пайки, пупком, спектры, рубан...</td>\n",
       "      <td>пупком тягнуть, тягнуть спектры, не аничковом,...</td>\n",
       "      <td>паники, пайки, пупком, рубанула, ибо, щурясь, ...</td>\n",
       "      <td>собирали паники, собирали пайки, мать пупком, ...</td>\n",
       "      <td>амулет, дом, побежать</td>\n",
       "      <td>гамлета, домовым, поберегите</td>\n",
       "      <td>паники, пайки, пупком, рубанула, ибо, щурясь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Sib_13-f</td>\n",
       "      <td>родились мы с братом тысяча девятьсот сороково...</td>\n",
       "      <td>недолго, холод, вани, бедно, крапиву, созерцал...</td>\n",
       "      <td>мальчика недолго, что холод, у вани, встали бе...</td>\n",
       "      <td>долго, холодный, ани, принимать, светить, напо...</td>\n",
       "      <td>недолго, холод, вани, принималась, сети, напои...</td>\n",
       "      <td>недолго, холод, вани, бедно, крапиву, созерцал...</td>\n",
       "      <td>принималась гарбуза, гарбуза коровушка, питали...</td>\n",
       "      <td>недолго, холод, вани, бедно, крапиву, созерцал...</td>\n",
       "      <td>мальчика недолго, что холод, у вани, встали бе...</td>\n",
       "      <td>долго, холодный, ани, принимать, светить, напо...</td>\n",
       "      <td>недолго, холод, вани, принималась, сети, напои...</td>\n",
       "      <td>недолго, холод, вани, бедно, крапиву, созерцал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Sib_15-f</td>\n",
       "      <td>угу лошади и нас эвакуировали будь я в маленьк...</td>\n",
       "      <td>угу, катуни, таку, бурною, цветению, глуше, че...</td>\n",
       "      <td>угу лошади, его катуни, соки таку, берег бурно...</td>\n",
       "      <td>каунтить, такой, что, потихоньку, правильно, а...</td>\n",
       "      <td>катуни, таку, чем, потихонечку, правильных, ал...</td>\n",
       "      <td>угу, катуни, таку, бурною, цветению, глуше, че...</td>\n",
       "      <td>там пятигорске, пятигорске в, было багульник, ...</td>\n",
       "      <td>угу, катуни, таку, бурною, цветению, глуше, че...</td>\n",
       "      <td>угу лошади, его катуни, соки таку, берег бурно...</td>\n",
       "      <td>каунтить, такой, что, потихоньку, правильно, м...</td>\n",
       "      <td>катуни, таку, чем, потихонечку, правильных, мо...</td>\n",
       "      <td>угу, катуни, таку, бурною, цветению, глуше, че...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Sib_16-m</td>\n",
       "      <td>с четырнадцати лет я начал работать работал пр...</td>\n",
       "      <td>прицеп, комбайне, комбайн, надувался, рецептур...</td>\n",
       "      <td>работал прицеп, поводу комбайне, комбайне комб...</td>\n",
       "      <td>прицел, сук</td>\n",
       "      <td>прицеп, сучка</td>\n",
       "      <td>прицеп, комбайне, комбайн, надувался, рецептур...</td>\n",
       "      <td>надувался коммунар, коммунар рецептура, леспро...</td>\n",
       "      <td>прицеп, надувался, рецептура, комбайна, бароме...</td>\n",
       "      <td>работал прицеп, комбайн надувался, рецептура к...</td>\n",
       "      <td>прицел</td>\n",
       "      <td>прицеп</td>\n",
       "      <td>прицеп, надувался, рецептура, комбайна, бароме...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sib_17-m</td>\n",
       "      <td>ты хоть три сюжета три сюжета а которое я помо...</td>\n",
       "      <td>ва, спи, воронежа, штанцы, окошек, отара, почт...</td>\n",
       "      <td>было ва, воронеж спи, окраине воронежа, малень...</td>\n",
       "      <td>танец, тара, один, полуночь, отскочить, хлеб</td>\n",
       "      <td>штанцы, отара, она, полночь, отмочить, хлебная</td>\n",
       "      <td>ва, спи, воронежа, штанцы, окошек, отара, почт...</td>\n",
       "      <td>три масючка, масючка была, стоял нафту, нафту ...</td>\n",
       "      <td>ва, спи, воронежа, окошек, отара, почти, бирж,...</td>\n",
       "      <td>было ва, воронеж спи, окраине воронежа, штанцы...</td>\n",
       "      <td>тара, полуночь, отскочить, хлеб</td>\n",
       "      <td>отара, полночь, отмочить, хлебная</td>\n",
       "      <td>ва, спи, воронежа, окошек, отара, почти, бирж,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    audio_ID                               alphacep_transcripts  \\\n",
       "84  Sib_12-f  так оно и какуюнибудь игру сработает о чем не ...   \n",
       "85  Sib_13-f  родились мы с братом тысяча девятьсот сороково...   \n",
       "87  Sib_15-f  угу лошади и нас эвакуировали будь я в маленьк...   \n",
       "88  Sib_16-m  с четырнадцати лет я начал работать работал пр...   \n",
       "89  Sib_17-m  ты хоть три сюжета три сюжета а которое я помо...   \n",
       "\n",
       "                                             mistakes  \\\n",
       "84  киберов, паники, пайки, пупком, спектры, рубан...   \n",
       "85  недолго, холод, вани, бедно, крапиву, созерцал...   \n",
       "87  угу, катуни, таку, бурною, цветению, глуше, че...   \n",
       "88  прицеп, комбайне, комбайн, надувался, рецептур...   \n",
       "89  ва, спи, воронежа, штанцы, окошек, отара, почт...   \n",
       "\n",
       "                                          bigram_mist  \\\n",
       "84  не киберов, собирали паники, собирали пайки, м...   \n",
       "85  мальчика недолго, что холод, у вани, встали бе...   \n",
       "87  угу лошади, его катуни, соки таку, берег бурно...   \n",
       "88  работал прицеп, поводу комбайне, комбайне комб...   \n",
       "89  было ва, воронеж спи, окраине воронежа, малень...   \n",
       "\n",
       "                                            new_words  \\\n",
       "84   кибермэн, сектор, амулет, собрать, дом, побежать   \n",
       "85  долго, холодный, ани, принимать, светить, напо...   \n",
       "87  каунтить, такой, что, потихоньку, правильно, а...   \n",
       "88                                        прицел, сук   \n",
       "89       танец, тара, один, полуночь, отскочить, хлеб   \n",
       "\n",
       "                                    mistakes_1st_type  \\\n",
       "84  киберов, спектры, гамлета, собирать, домовым, ...   \n",
       "85  недолго, холод, вани, принималась, сети, напои...   \n",
       "87  катуни, таку, чем, потихонечку, правильных, ал...   \n",
       "88                                      прицеп, сучка   \n",
       "89     штанцы, отара, она, полночь, отмочить, хлебная   \n",
       "\n",
       "                                    mistakes_2nd_type  \\\n",
       "84  киберов, паники, пайки, пупком, спектры, рубан...   \n",
       "85  недолго, холод, вани, бедно, крапиву, созерцал...   \n",
       "87  угу, катуни, таку, бурною, цветению, глуше, че...   \n",
       "88  прицеп, комбайне, комбайн, надувался, рецептур...   \n",
       "89  ва, спи, воронежа, штанцы, окошек, отара, почт...   \n",
       "\n",
       "                                         absent_words  \\\n",
       "84  пупком тягнуть, тягнуть спектры, не аничковом,...   \n",
       "85  принималась гарбуза, гарбуза коровушка, питали...   \n",
       "87  там пятигорске, пятигорске в, было багульник, ...   \n",
       "88  надувался коммунар, коммунар рецептура, леспро...   \n",
       "89  три масючка, масючка была, стоял нафту, нафту ...   \n",
       "\n",
       "                                         w2v_mistakes  \\\n",
       "84  паники, пайки, пупком, рубанула, ибо, щурясь, ...   \n",
       "85  недолго, холод, вани, бедно, крапиву, созерцал...   \n",
       "87  угу, катуни, таку, бурною, цветению, глуше, че...   \n",
       "88  прицеп, надувался, рецептура, комбайна, бароме...   \n",
       "89  ва, спи, воронежа, окошек, отара, почти, бирж,...   \n",
       "\n",
       "                                      w2v_bigram_mist  \\\n",
       "84  собирали паники, собирали пайки, мать пупком, ...   \n",
       "85  мальчика недолго, что холод, у вани, встали бе...   \n",
       "87  угу лошади, его катуни, соки таку, берег бурно...   \n",
       "88  работал прицеп, комбайн надувался, рецептура к...   \n",
       "89  было ва, воронеж спи, окраине воронежа, штанцы...   \n",
       "\n",
       "                                        w2v_new_words  \\\n",
       "84                              амулет, дом, побежать   \n",
       "85  долго, холодный, ани, принимать, светить, напо...   \n",
       "87  каунтить, такой, что, потихоньку, правильно, м...   \n",
       "88                                             прицел   \n",
       "89                    тара, полуночь, отскочить, хлеб   \n",
       "\n",
       "                                w2v_mistakes_1st_type  \\\n",
       "84                       гамлета, домовым, поберегите   \n",
       "85  недолго, холод, вани, принималась, сети, напои...   \n",
       "87  катуни, таку, чем, потихонечку, правильных, мо...   \n",
       "88                                             прицеп   \n",
       "89                  отара, полночь, отмочить, хлебная   \n",
       "\n",
       "                                w2v_mistakes_2nd_type  \n",
       "84  паники, пайки, пупком, рубанула, ибо, щурясь, ...  \n",
       "85  недолго, холод, вани, бедно, крапиву, созерцал...  \n",
       "87  угу, катуни, таку, бурною, цветению, глуше, че...  \n",
       "88  прицеп, надувался, рецептура, комбайна, бароме...  \n",
       "89  ва, спи, воронежа, окошек, отара, почти, бирж,...  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_alpha.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Корпус транскрибатора АБК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 9.06 µs\n",
      "Обрабатываю ряд  35\n",
      "\tВсего ошибок:  10  из  148\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово дяденька_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  36\n",
      "\tВсего ошибок:  21  из  135\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  37\n",
      "\tВсего ошибок:  6  из  94\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  38\n",
      "\tВсего ошибок:  20  из  87\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  39\n",
      "\tВсего ошибок:  11  из  87\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  40\n",
      "\tВсего ошибок:  17  из  141\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  41\n",
      "\tВсего ошибок:  3  из  51\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  42\n",
      "\tВсего ошибок:  9  из  64\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово сняться_VERB не ошибка\n",
      "Обрабатываю ряд  43\n",
      "\tВсего ошибок:  20  из  116\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово подарочек_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  44\n",
      "\tВсего ошибок:  6  из  99\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  45\n",
      "\tВсего ошибок:  16  из  84\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  46\n",
      "\tВсего ошибок:  17  из  61\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Слово покушать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  47\n",
      "\tВсего ошибок:  8  из  77\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  48\n",
      "\tВсего ошибок:  10  из  76\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово расстроиться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  49\n",
      "\tВсего ошибок:  5  из  82\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  50\n",
      "\tВсего ошибок:  9  из  80\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово позавтракать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово возмещать_VERB не ошибка\n",
      "Обрабатываю ряд  51\n",
      "\tВсего ошибок:  56  из  206\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово подходить_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово торговать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово ошибаться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  52\n",
      "\tВсего ошибок:  28  из  112\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово литься_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  53\n",
      "\tВсего ошибок:  24  из  102\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово передвигаться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  54\n",
      "\tВсего ошибок:  11  из  99\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  55\n",
      "\tВсего ошибок:  6  из  39\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  56\n",
      "\tВсего ошибок:  2  из  82\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Обрабатываю ряд  57\n",
      "\tВсего ошибок:  4  из  34\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  58\n",
      "\tВсего ошибок:  12  из  55\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Слово денежка_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово выпевать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  59\n",
      "\tВсего ошибок:  24  из  103\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово цена_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово автомобиль_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово расстроиться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  60\n",
      "\tВсего ошибок:  28  из  119\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово ключик_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово поворачиваться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  61\n",
      "\tВсего ошибок:  16  из  82\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  62\n",
      "\tВсего ошибок:  14  из  86\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово переломать_VERB не ошибка\n",
      "Обрабатываю ряд  63\n",
      "\tВсего ошибок:  10  из  100\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово полезть_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  64\n",
      "\tВсего ошибок:  20  из  98\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово отказаться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  65\n",
      "\tВсего ошибок:  11  из  99\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово прослушать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово позавтракать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  66\n",
      "\tВсего ошибок:  23  из  86\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Слово слушать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово покататься_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  67\n",
      "\tВсего ошибок:  21  из  88\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово отоспаться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово сумочка_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово посмотреть_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  68\n",
      "\tВсего ошибок:  11  из  89\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  69\n",
      "\tВсего ошибок:  11  из  54\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  70\n",
      "\tВсего ошибок:  16  из  84\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  4\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово листочек_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  71\n",
      "\tВсего ошибок:  23  из  126\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  0\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово свечка_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово сюда_ADV не ошибка\n",
      "Обрабатываю ряд  72\n",
      "\tВсего ошибок:  18  из  68\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Слово горка_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово ехать_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  75\n",
      "\tВсего ошибок:  27  из  85\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  2\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово заканчиваться_VERB не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово миллион_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  76\n",
      "\tВсего ошибок:  33  из  149\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  8\n",
      "Ключ есть в модели word2vec\n",
      "Слово технолог_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово опять_ADV не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Обрабатываю ряд  78\n",
      "\tВсего ошибок:  6  из  39\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  1\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово потом_ADV не ошибка\n",
      "Обрабатываю ряд  86\n",
      "\tВсего ошибок:  10  из  69\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  4\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово лето_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n",
      "Слово гряда_NOUN не ошибка\n",
      "Обрабатываю ряд  88\n",
      "\tВсего ошибок:  23  из  79\n",
      "\tКоличество биграм с отсутствующим в словаре словом:  6\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Ключ есть в модели word2vec\n",
      "Слово тракт_NOUN не ошибка\n",
      "Ключ есть в модели word2vec\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "trans_abk['mistakes'] = ''\n",
    "trans_abk['bigram_mist'] = ''\n",
    "trans_abk['new_words'] = ''\n",
    "trans_abk['mistakes_1st_type'] = ''\n",
    "trans_abk['mistakes_2nd_type'] = ''\n",
    "trans_abk['absent_words'] = ''\n",
    "\n",
    "trans_abk['w2v_mistakes'] = ''\n",
    "trans_abk['w2v_bigram_mist'] = ''\n",
    "trans_abk['w2v_new_words'] = ''\n",
    "trans_abk['w2v_mistakes_1st_type'] = ''\n",
    "trans_abk['w2v_mistakes_2nd_type'] = ''\n",
    "\n",
    "\n",
    "for row in trans_abk.abk_transcripts.index:\n",
    "    print('Обрабатываю ряд ', row)\n",
    "    text = insert_hyphen_in_text(trans_abk.abk_transcripts[row], hyphened_words)\n",
    "    mistakes, bigrams_prob_dict, no_such_word = find_mistakes(text, cfreq, cprob)\n",
    "    true_mistakes = find_true_mistakes(mistakes, bigrams_prob_dict)\n",
    "    leven_mist = find_variation(vocab, true_mistakes)\n",
    "    \n",
    "    first_mistakes, second_mistakes, new_words = categorize_mistakes(leven_mist, true_mistakes, cprob)\n",
    "    \n",
    "    tagged_true_mistakes = insert_pos_tags(true_mistakes, mapping_Pymorphy_UPos)\n",
    "    filtered_true_mistakes, not_mistakes, no_UDPos_tags  = filter_mistakes_with_cos_similarity(tagged_true_mistakes, w2v_tayga_model, cprob, true_mistakes)\n",
    "    w2v_leven_mist = find_variation(vocab, filtered_true_mistakes)\n",
    "    \n",
    "    \n",
    "    w2v_first_mistakes, w2v_second_mistakes, w2v_new_words = categorize_mistakes(w2v_leven_mist, filtered_true_mistakes, cprob)\n",
    "    \n",
    "    trans_abk['mistakes'][row] = ', '.join([key for key in true_mistakes])\n",
    "    trans_abk['bigram_mist'][row] = ', '.join([true_mistakes[key] for key in true_mistakes])\n",
    "    trans_abk['new_words'][row] =', '.join(new_words)\n",
    "    trans_abk['absent_words'][row] = ', '.join(no_such_word)\n",
    "    trans_abk['mistakes_1st_type'][row] = ', '.join(first_mistakes)\n",
    "    trans_abk['mistakes_2nd_type'][row] = ', '.join(second_mistakes)\n",
    "    \n",
    "    trans_abk['w2v_mistakes'][row] = ', '.join([key for key in filtered_true_mistakes])\n",
    "    trans_abk['w2v_bigram_mist'][row] = ', '.join([filtered_true_mistakes[key] for key in filtered_true_mistakes])\n",
    "    trans_abk['w2v_new_words'][row] =', '.join(w2v_new_words)\n",
    "    trans_abk['w2v_mistakes_1st_type'][row] = ', '.join(w2v_first_mistakes)\n",
    "    trans_abk['w2v_mistakes_2nd_type'][row] = ', '.join(w2v_second_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>abk_transcripts</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>bigram_mist</th>\n",
       "      <th>new_words</th>\n",
       "      <th>mistakes_1st_type</th>\n",
       "      <th>mistakes_2nd_type</th>\n",
       "      <th>absent_words</th>\n",
       "      <th>w2v_mistakes</th>\n",
       "      <th>w2v_bigram_mist</th>\n",
       "      <th>w2v_new_words</th>\n",
       "      <th>w2v_mistakes_1st_type</th>\n",
       "      <th>w2v_mistakes_2nd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pic-RUS_01-f_Pr-R.zip</td>\n",
       "      <td>жил был один дяденька его жены скоро должно бы...</td>\n",
       "      <td>дяденька, снова</td>\n",
       "      <td>один дяденька, осталось снова</td>\n",
       "      <td>дядька, новый</td>\n",
       "      <td>дяденька, снова</td>\n",
       "      <td>дяденька, снова</td>\n",
       "      <td>один дячка, дячка заявил</td>\n",
       "      <td>снова</td>\n",
       "      <td>осталось снова</td>\n",
       "      <td>новый</td>\n",
       "      <td>снова</td>\n",
       "      <td>снова</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pic-RUS_01-f_Pr-T.zip</td>\n",
       "      <td>товарищ тут с ним случилось проблема у его жен...</td>\n",
       "      <td>товарищ, какие-нибудь, присоветует, ильич, нот...</td>\n",
       "      <td>товарищ тут, какое-нибудь какие-нибудь, думаю ...</td>\n",
       "      <td>товар, посоветовать</td>\n",
       "      <td>товарищ, присоветует</td>\n",
       "      <td>товарищ, какие-нибудь, присоветует, ильич, нот...</td>\n",
       "      <td></td>\n",
       "      <td>товарищ, какие-нибудь, присоветует, ильич, нот...</td>\n",
       "      <td>товарищ тут, какое-нибудь какие-нибудь, думаю ...</td>\n",
       "      <td>товар, посоветовать</td>\n",
       "      <td>товарищ, присоветует</td>\n",
       "      <td>товарищ, какие-нибудь, присоветует, ильич, нот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pic-RUS_01-f_Ski-R.zip</td>\n",
       "      <td>жил был один молодой человек это молодой челов...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pic-RUS_01-f_Ski-T.zip</td>\n",
       "      <td>день жизнь одного точне увлекающейся спорту му...</td>\n",
       "      <td>точне, товарищ, человека, заряд, нажрался, мил...</td>\n",
       "      <td>одного точне, спортивный товарищ, выпиской чел...</td>\n",
       "      <td>точный, вложить</td>\n",
       "      <td>точне, ложили</td>\n",
       "      <td>точне, товарищ, человека, заряд, нажрался, мил...</td>\n",
       "      <td></td>\n",
       "      <td>точне, товарищ, человека, заряд, нажрался, мил...</td>\n",
       "      <td>одного точне, спортивный товарищ, выпиской чел...</td>\n",
       "      <td>точный, вложить</td>\n",
       "      <td>точне, ложили</td>\n",
       "      <td>точне, товарищ, человека, заряд, нажрался, мил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pic-RUS_02-f_Pr-R.zip</td>\n",
       "      <td>однозначно был день рождения её муж решил пода...</td>\n",
       "      <td>грушой, машинку</td>\n",
       "      <td>маленькой грушой, грушой машинку</td>\n",
       "      <td>игрушка</td>\n",
       "      <td>грушой</td>\n",
       "      <td>грушой, машинку</td>\n",
       "      <td></td>\n",
       "      <td>грушой, машинку</td>\n",
       "      <td>маленькой грушой, грушой машинку</td>\n",
       "      <td>игрушка</td>\n",
       "      <td>грушой</td>\n",
       "      <td>грушой, машинку</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  audio_ID                                    abk_transcripts  \\\n",
       "35   Pic-RUS_01-f_Pr-R.zip  жил был один дяденька его жены скоро должно бы...   \n",
       "36   Pic-RUS_01-f_Pr-T.zip  товарищ тут с ним случилось проблема у его жен...   \n",
       "37  Pic-RUS_01-f_Ski-R.zip  жил был один молодой человек это молодой челов...   \n",
       "38  Pic-RUS_01-f_Ski-T.zip  день жизнь одного точне увлекающейся спорту му...   \n",
       "39   Pic-RUS_02-f_Pr-R.zip  однозначно был день рождения её муж решил пода...   \n",
       "\n",
       "                                             mistakes  \\\n",
       "35                                    дяденька, снова   \n",
       "36  товарищ, какие-нибудь, присоветует, ильич, нот...   \n",
       "37                                                      \n",
       "38  точне, товарищ, человека, заряд, нажрался, мил...   \n",
       "39                                    грушой, машинку   \n",
       "\n",
       "                                          bigram_mist            new_words  \\\n",
       "35                      один дяденька, осталось снова        дядька, новый   \n",
       "36  товарищ тут, какое-нибудь какие-нибудь, думаю ...  товар, посоветовать   \n",
       "37                                                                           \n",
       "38  одного точне, спортивный товарищ, выпиской чел...      точный, вложить   \n",
       "39                   маленькой грушой, грушой машинку              игрушка   \n",
       "\n",
       "       mistakes_1st_type                                  mistakes_2nd_type  \\\n",
       "35       дяденька, снова                                    дяденька, снова   \n",
       "36  товарищ, присоветует  товарищ, какие-нибудь, присоветует, ильич, нот...   \n",
       "37                                                                            \n",
       "38         точне, ложили  точне, товарищ, человека, заряд, нажрался, мил...   \n",
       "39                грушой                                    грушой, машинку   \n",
       "\n",
       "                absent_words  \\\n",
       "35  один дячка, дячка заявил   \n",
       "36                             \n",
       "37                             \n",
       "38                             \n",
       "39                             \n",
       "\n",
       "                                         w2v_mistakes  \\\n",
       "35                                              снова   \n",
       "36  товарищ, какие-нибудь, присоветует, ильич, нот...   \n",
       "37                                                      \n",
       "38  точне, товарищ, человека, заряд, нажрался, мил...   \n",
       "39                                    грушой, машинку   \n",
       "\n",
       "                                      w2v_bigram_mist        w2v_new_words  \\\n",
       "35                                     осталось снова                новый   \n",
       "36  товарищ тут, какое-нибудь какие-нибудь, думаю ...  товар, посоветовать   \n",
       "37                                                                           \n",
       "38  одного точне, спортивный товарищ, выпиской чел...      точный, вложить   \n",
       "39                   маленькой грушой, грушой машинку              игрушка   \n",
       "\n",
       "   w2v_mistakes_1st_type                              w2v_mistakes_2nd_type  \n",
       "35                 снова                                              снова  \n",
       "36  товарищ, присоветует  товарищ, какие-нибудь, присоветует, ильич, нот...  \n",
       "37                                                                           \n",
       "38         точне, ложили  точне, товарищ, человека, заряд, нажрался, мил...  \n",
       "39                грушой                                    грушой, машинку  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_abk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>abk_transcripts</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>bigram_mist</th>\n",
       "      <th>new_words</th>\n",
       "      <th>mistakes_1st_type</th>\n",
       "      <th>mistakes_2nd_type</th>\n",
       "      <th>absent_words</th>\n",
       "      <th>w2v_mistakes</th>\n",
       "      <th>w2v_bigram_mist</th>\n",
       "      <th>w2v_new_words</th>\n",
       "      <th>w2v_mistakes_1st_type</th>\n",
       "      <th>w2v_mistakes_2nd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Sib_03-m</td>\n",
       "      <td>да роман и девятнадцать лет родился в городе у...</td>\n",
       "      <td>улан-удэ, здесь, геннадьевич, сидорова, сибиря...</td>\n",
       "      <td>городе улан-удэ, улан-удэ здесь, еще геннадьев...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>улан-удэ, здесь, геннадьевич, сидорова, сибиря...</td>\n",
       "      <td>этого шаликоевич, шаликоевич который</td>\n",
       "      <td>улан-удэ, здесь, геннадьевич, сидорова, сибиря...</td>\n",
       "      <td>городе улан-удэ, улан-удэ здесь, еще геннадьев...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>улан-удэ, здесь, геннадьевич, сидорова, сибиря...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Sib_04-m</td>\n",
       "      <td>малики ругались на меня судя по всему год отра...</td>\n",
       "      <td>малики, технолог, попросил, вычел, выдаче, тен...</td>\n",
       "      <td>малики ругались, мне технолог, технолог попрос...</td>\n",
       "      <td>технология, любопытный, пять, тащить, стартова...</td>\n",
       "      <td>технолог, опытных, опять, тащились, старт, поя...</td>\n",
       "      <td>малики, технолог, попросил, вычел, выдаче, тен...</td>\n",
       "      <td>тень альфия, альфия четвертой, опытных фрезеро...</td>\n",
       "      <td>малики, попросил, вычел, выдаче, тень, григори...</td>\n",
       "      <td>малики ругались, технолог попросил, деталь выч...</td>\n",
       "      <td>любопытный, тащить, стартовать, появляться</td>\n",
       "      <td>опытных, тащились, старт, появился</td>\n",
       "      <td>малики, попросил, вычел, выдаче, тень, григори...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Sib_06-f</td>\n",
       "      <td>ламанову что я побежала в школу не понимала чт...</td>\n",
       "      <td>лосева, чисел, потом</td>\n",
       "      <td>улице лосева, поймал чисел, чисел потом</td>\n",
       "      <td>простой</td>\n",
       "      <td>потом</td>\n",
       "      <td>лосева, чисел, потом</td>\n",
       "      <td>ламанову что</td>\n",
       "      <td>лосева, чисел</td>\n",
       "      <td>улице лосева, поймал чисел</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>лосева, чисел</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Sib_14-f</td>\n",
       "      <td>третьего года начало самой дачный сезон живу с...</td>\n",
       "      <td>живу, лето, грядах</td>\n",
       "      <td>сезон живу, ночи лето, меньше грядах</td>\n",
       "      <td>живой, этот</td>\n",
       "      <td>живу, лето</td>\n",
       "      <td>живу, лето, грядах</td>\n",
       "      <td>ухаживать варичем, варичем живут, удачный ураз...</td>\n",
       "      <td>живу</td>\n",
       "      <td>сезон живу</td>\n",
       "      <td>живой</td>\n",
       "      <td>живу</td>\n",
       "      <td>живу</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Sib_16-m</td>\n",
       "      <td>сейчас силе я начал работать работу вообще на ...</td>\n",
       "      <td>комбайне, комбайн, назывался, любые, коне, бог...</td>\n",
       "      <td>на комбайне, комбайне комбайн, комбайн называл...</td>\n",
       "      <td>любимый, конь, траут</td>\n",
       "      <td>любые, коне, тракта</td>\n",
       "      <td>комбайне, комбайн, назывался, любые, коне, бог...</td>\n",
       "      <td>назывался коммунар, коммунар любые, коне борон...</td>\n",
       "      <td>комбайн, назывался, любые, коне, богатырский, ...</td>\n",
       "      <td>комбайне комбайн, комбайн назывался, любые пот...</td>\n",
       "      <td>любимый, конь</td>\n",
       "      <td>любые, коне</td>\n",
       "      <td>комбайн, назывался, любые, коне, богатырский, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    audio_ID                                    abk_transcripts  \\\n",
       "75  Sib_03-m  да роман и девятнадцать лет родился в городе у...   \n",
       "76  Sib_04-m  малики ругались на меня судя по всему год отра...   \n",
       "78  Sib_06-f  ламанову что я побежала в школу не понимала чт...   \n",
       "86  Sib_14-f  третьего года начало самой дачный сезон живу с...   \n",
       "88  Sib_16-m  сейчас силе я начал работать работу вообще на ...   \n",
       "\n",
       "                                             mistakes  \\\n",
       "75  улан-удэ, здесь, геннадьевич, сидорова, сибиря...   \n",
       "76  малики, технолог, попросил, вычел, выдаче, тен...   \n",
       "78                               лосева, чисел, потом   \n",
       "86                                 живу, лето, грядах   \n",
       "88  комбайне, комбайн, назывался, любые, коне, бог...   \n",
       "\n",
       "                                          bigram_mist  \\\n",
       "75  городе улан-удэ, улан-удэ здесь, еще геннадьев...   \n",
       "76  малики ругались, мне технолог, технолог попрос...   \n",
       "78            улице лосева, поймал чисел, чисел потом   \n",
       "86               сезон живу, ночи лето, меньше грядах   \n",
       "88  на комбайне, комбайне комбайн, комбайн называл...   \n",
       "\n",
       "                                            new_words  \\\n",
       "75                                                      \n",
       "76  технология, любопытный, пять, тащить, стартова...   \n",
       "78                                            простой   \n",
       "86                                        живой, этот   \n",
       "88                               любимый, конь, траут   \n",
       "\n",
       "                                    mistakes_1st_type  \\\n",
       "75                                                      \n",
       "76  технолог, опытных, опять, тащились, старт, поя...   \n",
       "78                                              потом   \n",
       "86                                         живу, лето   \n",
       "88                                любые, коне, тракта   \n",
       "\n",
       "                                    mistakes_2nd_type  \\\n",
       "75  улан-удэ, здесь, геннадьевич, сидорова, сибиря...   \n",
       "76  малики, технолог, попросил, вычел, выдаче, тен...   \n",
       "78                               лосева, чисел, потом   \n",
       "86                                 живу, лето, грядах   \n",
       "88  комбайне, комбайн, назывался, любые, коне, бог...   \n",
       "\n",
       "                                         absent_words  \\\n",
       "75               этого шаликоевич, шаликоевич который   \n",
       "76  тень альфия, альфия четвертой, опытных фрезеро...   \n",
       "78                                       ламанову что   \n",
       "86  ухаживать варичем, варичем живут, удачный ураз...   \n",
       "88  назывался коммунар, коммунар любые, коне борон...   \n",
       "\n",
       "                                         w2v_mistakes  \\\n",
       "75  улан-удэ, здесь, геннадьевич, сидорова, сибиря...   \n",
       "76  малики, попросил, вычел, выдаче, тень, григори...   \n",
       "78                                      лосева, чисел   \n",
       "86                                               живу   \n",
       "88  комбайн, назывался, любые, коне, богатырский, ...   \n",
       "\n",
       "                                      w2v_bigram_mist  \\\n",
       "75  городе улан-удэ, улан-удэ здесь, еще геннадьев...   \n",
       "76  малики ругались, технолог попросил, деталь выч...   \n",
       "78                         улице лосева, поймал чисел   \n",
       "86                                         сезон живу   \n",
       "88  комбайне комбайн, комбайн назывался, любые пот...   \n",
       "\n",
       "                                 w2v_new_words  \\\n",
       "75                                               \n",
       "76  любопытный, тащить, стартовать, появляться   \n",
       "78                                               \n",
       "86                                       живой   \n",
       "88                               любимый, конь   \n",
       "\n",
       "                 w2v_mistakes_1st_type  \\\n",
       "75                                       \n",
       "76  опытных, тащились, старт, появился   \n",
       "78                                       \n",
       "86                                живу   \n",
       "88                         любые, коне   \n",
       "\n",
       "                                w2v_mistakes_2nd_type  \n",
       "75  улан-удэ, здесь, геннадьевич, сидорова, сибиря...  \n",
       "76  малики, попросил, вычел, выдаче, тень, григори...  \n",
       "78                                      лосева, чисел  \n",
       "86                                               живу  \n",
       "88  комбайн, назывался, любые, коне, богатырский, ...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_abk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abk.to_excel('trans_abk_w2v.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка алгоритма c моделью Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузка файлов для разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_alpha = pd.DataFrame({'word':[], 'true':0, 'pred':0})\n",
    "for ind in [35, 38, 39, 45, 46, 62, 64, 65, 66, 88]:\n",
    "    score = pd.DataFrame({'word':trans_alpha.alphacep_transcripts[ind].split()})\n",
    "    score['true'] = 0\n",
    "    score['pred'] = 0\n",
    "    score.to_excel(str(ind)+'score_alpha_w2vec.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_abk = pd.DataFrame({'word':[], 'true':0, 'pred':0})\n",
    "for ind in [35, 38, 39, 45, 46, 62, 64, 65, 66, 88]:\n",
    "    score = pd.DataFrame({'word':trans_abk.abk_transcripts[ind].split()})\n",
    "    score['true'] = 0\n",
    "    score['pred'] = 0\n",
    "    score.to_excel(str(ind)+'score_abk_w2vec.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка размеченных файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_alpha = ['35score_alpha_w2vec.xlsx','38score_alpha_w2vec.xlsx','39score_alpha_w2vec.xlsx','45score_alpha_w2vec.xlsx','46score_alpha_w2vec.xlsx', '62score_alpha_w2vec.xlsx','64score_alpha_w2vec.xlsx','65score_alpha_w2vec.xlsx','66score_alpha_w2vec.xlsx','88score_alpha_w2vec.xlsx']\n",
    "files_abk = ['35score_abk_w2vec.xlsx','38score_abk_w2vec.xlsx','39score_abk_w2vec.xlsx','45score_abk_w2vec.xlsx','46score_abk_w2vec.xlsx', '62score_abk_w2vec.xlsx','64score_abk_w2vec.xlsx','65score_abk_w2vec.xlsx','66score_abk_w2vec.xlsx','88score_abk_w2vec.xlsx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формирование значений y_true для транскрибаций alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_alpha = []\n",
    "y_pred_alpha = []\n",
    "for file in files_alpha:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_true_alpha+=y_true \n",
    "    y_pred = list(df.pred)\n",
    "    y_pred_alpha += y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формирование значений y_true для транскрибаций abk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_abk = []\n",
    "y_pred_abk = []\n",
    "for file in files_abk:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_true_abk+=y_true \n",
    "    y_pred = list(df.pred)\n",
    "    y_pred_abk += y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подсчет метрик для всех транскрибаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all alphacep transcriptions:\n",
      "\tPrecision: 0.6301\n",
      "\tRecall: 0.4107\n",
      "\tF1: 0.4973\n",
      "\tAccuracy: 0.9071\n"
     ]
    }
   ],
   "source": [
    "print('For all alphacep transcriptions:')\n",
    "print('\\tPrecision: {:0.4f}'.format(precision_score(y_true_alpha, y_pred_alpha)))\n",
    "print('\\tRecall: {:0.4f}'.format(recall_score(y_true_alpha, y_pred_alpha)))\n",
    "print('\\tF1: {:0.4f}'.format(f1_score(y_true_alpha, y_pred_alpha)))\n",
    "print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true_alpha, y_pred_alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all ABK transcriptions:\n",
      "\tPrecision: 0.4833\n",
      "\tRecall: 0.2000\n",
      "\tF1: 0.2829\n",
      "\tAccuracy: 0.8485\n"
     ]
    }
   ],
   "source": [
    "print('For all ABK transcriptions:')\n",
    "print('\\tPrecision: {:0.4f}'.format(precision_score(y_true_abk, y_pred_abk)))\n",
    "print('\\tRecall: {:0.4f}'.format(recall_score(y_true_abk, y_pred_abk)))\n",
    "print('\\tF1: {:0.4f}'.format(f1_score(y_true_abk, y_pred_abk)))\n",
    "print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true_abk, y_pred_abk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подсчет метрик отдельно для каждой транскрибации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For file: 35score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.7778\n",
      "\tRecall: 0.4375\n",
      "\tF1: 0.5600\n",
      "\tAccuracy: 0.9231\n",
      "For file: 38score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.6250\n",
      "\tRecall: 0.7143\n",
      "\tF1: 0.6667\n",
      "\tAccuracy: 0.9412\n",
      "For file: 39score_alpha_w2vec.xlsx\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.1667\n",
      "\tF1: 0.2857\n",
      "\tAccuracy: 0.9383\n",
      "For file: 45score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.8000\n",
      "\tRecall: 0.6667\n",
      "\tF1: 0.7273\n",
      "\tAccuracy: 0.9651\n",
      "For file: 46score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.3333\n",
      "\tRecall: 0.1429\n",
      "\tF1: 0.2000\n",
      "\tAccuracy: 0.8857\n",
      "For file: 62score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.5000\n",
      "\tRecall: 0.2222\n",
      "\tF1: 0.3077\n",
      "\tAccuracy: 0.9143\n",
      "For file: 64score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.4615\n",
      "\tRecall: 0.3158\n",
      "\tF1: 0.3750\n",
      "\tAccuracy: 0.8165\n",
      "For file: 65score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.0000\n",
      "\tRecall: 0.0000\n",
      "\tF1: 0.0000\n",
      "\tAccuracy: 1.0000\n",
      "For file: 66score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.5714\n",
      "\tRecall: 0.3077\n",
      "\tF1: 0.4000\n",
      "\tAccuracy: 0.8788\n",
      "For file: 88score_alpha_w2vec.xlsx\n",
      "\tPrecision: 0.6957\n",
      "\tRecall: 0.5517\n",
      "\tF1: 0.6154\n",
      "\tAccuracy: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for file in files_alpha:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_pred = list(df.pred)\n",
    "    print('For file:', file)\n",
    "    print('\\tPrecision: {:0.4f}'.format(precision_score(y_true, y_pred)))\n",
    "    print('\\tRecall: {:0.4f}'.format(recall_score(y_true, y_pred)))\n",
    "    print('\\tF1: {:0.4f}'.format(f1_score(y_true, y_pred)))\n",
    "    print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For file: 35score_abk_w2vec.xlsx\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.1429\n",
      "\tF1: 0.2500\n",
      "\tAccuracy: 0.9231\n",
      "For file: 38score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.4444\n",
      "\tRecall: 0.6667\n",
      "\tF1: 0.5333\n",
      "\tAccuracy: 0.9231\n",
      "For file: 39score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.5000\n",
      "\tRecall: 0.0667\n",
      "\tF1: 0.1176\n",
      "\tAccuracy: 0.8333\n",
      "For file: 45score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.7500\n",
      "\tRecall: 0.3750\n",
      "\tF1: 0.5000\n",
      "\tAccuracy: 0.9310\n",
      "For file: 46score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.3333\n",
      "\tRecall: 0.2500\n",
      "\tF1: 0.2857\n",
      "\tAccuracy: 0.8438\n",
      "For file: 62score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.0000\n",
      "\tRecall: 0.0000\n",
      "\tF1: 0.0000\n",
      "\tAccuracy: 0.9126\n",
      "For file: 64score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.3333\n",
      "\tRecall: 0.2143\n",
      "\tF1: 0.2609\n",
      "\tAccuracy: 0.8333\n",
      "For file: 65score_abk_w2vec.xlsx\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.0741\n",
      "\tF1: 0.1379\n",
      "\tAccuracy: 0.7596\n",
      "For file: 66score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.5556\n",
      "\tRecall: 0.2632\n",
      "\tF1: 0.3571\n",
      "\tAccuracy: 0.8022\n",
      "For file: 88score_abk_w2vec.xlsx\n",
      "\tPrecision: 0.4667\n",
      "\tRecall: 0.2593\n",
      "\tF1: 0.3333\n",
      "\tAccuracy: 0.6585\n"
     ]
    }
   ],
   "source": [
    "for file in files_abk:\n",
    "    df = pd.read_excel(file)\n",
    "    y_true = list(df.true)\n",
    "    y_pred = list(df.pred)\n",
    "    print('For file:', file)\n",
    "    print('\\tPrecision: {:0.4f}'.format(precision_score(y_true, y_pred)))\n",
    "    print('\\tRecall: {:0.4f}'.format(recall_score(y_true, y_pred)))\n",
    "    print('\\tF1: {:0.4f}'.format(f1_score(y_true, y_pred)))\n",
    "    print('\\tAccuracy: {:0.4f}'.format(accuracy_score(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
